{"version":3,"sources":["webpack:///webpack/bootstrap b9a9c9e3da985e86b33e?856c","webpack:///./src/index.js","webpack:///../src/filters.js","webpack:///../~/tracking/build/tracking.js","webpack:///../src/filterTask.js","webpack:///../src/filter.js","webpack:///../src/mock-get-user-media.js"],"names":[],"mappings":";AAAA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,uBAAe;AACf;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;;;;;;ACtCA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,EAAC;;;AAGD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAK;AACL,IAAG;;AAEH;AACA;AACA;AACA;AACA,MAAK;AACL;AACA,IAAG;AACH,EAAC;;;;;;;;;ACrCD;AACA;AACA;;AAEA;AACA;AACA,kBAAiB,yBAAyB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,IAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,IAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,IAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,IAAG;AACH;AACA;AACA;AACA,sBAAqB,yBAAyB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAW;AACX;AACA;AACA;AACA;AACA;AACA,UAAS;;AAET;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,QAAO;AACP;AACA;AACA;AACA,IAAG;AACH;;;;;;;AC1HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,kCAAiC;AACjC,+CAA8C;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAa,SAAS;AACtB,cAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAe,QAAQ;AACvB,gBAAe,OAAO;AACtB;AACA,gBAAe,KAAK;AACpB;AACA,iBAAgB,EAAE;AAClB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,cAAa,iBAAiB;AAC9B,cAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA,MAAK;AACL;AACA;AACA,UAAS;AACT;AACA;AACA,QAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB,eAAc,QAAQ;AACtB;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB,eAAc,QAAQ;AACtB;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB;AACA,eAAc,YAAY;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAwC,eAAe;AACvD;AACA;AACA;AACA,OAAM;AACN;AACA,cAAa,YAAY;AACzB;AACA,cAAa,iBAAiB;AAC9B;AACA,cAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,cAAa,kBAAkB;AAC/B,cAAa,iBAAiB;AAC9B;AACA,cAAa,OAAO;AACpB,eAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA,cAAa,kBAAkB;AAC/B,cAAa,iBAAiB;AAC9B;AACA,cAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,cAAa,iBAAiB;AAC9B,cAAa,iBAAiB;AAC9B;AACA,cAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,QAAO;AACP,MAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,cAAa,iBAAiB;AAC9B,cAAa,iBAAiB;AAC9B;AACA,cAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAW;AACX;AACA;AACA;AACA,QAAO;AACP;;AAEA;AACA;AACA;AACA,MAAK;AACL;AACA;AACA,MAAK;AACL;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,EAAC;;AAED;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAY;AACZ;AACA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,SAAS;AACtB,eAAc,OAAO;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB,eAAc,MAAM;AACpB;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,EAAE;AACf,eAAc,QAAQ;AACtB;AACA;AACA;AACA;AACA;AACA,sBAAqB,sBAAsB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,SAAS;AACtB,eAAc,OAAO;AACrB;AACA;;AAEA;AACA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,SAAS;AACtB,eAAc,OAAO;AACrB;AACA;AACA;AACA;AACA;AACA;AACA,MAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,cAAa,OAAO;AACpB,eAAc,OAAO;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,SAAS;AACtB,eAAc,OAAO;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,cAAa,OAAO;AACpB;AACA;AACA;AACA;;AAEA,EAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,kBAAkB;AAC/B,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,EAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA,oBAAmB,mBAAmB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAmB,YAAY;AAC/B;AACA;AACA;;AAEA;AACA;AACA,aAAY;AACZ;AACA;;AAEA;AACA;AACA,aAAY;AACZ;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB,eAAc,OAAO;AACrB;AACA;AACA;AACA;AACA,MAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;;AAEA,EAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,eAAc,MAAM;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAmB,SAAS;AAC5B;AACA;AACA;AACA;AACA;AACA,oBAAmB,oBAAoB;AACvC;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,MAAM;AACnB;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,MAAM;AACnB;AACA;AACA,cAAa,MAAM;AACnB;AACA;AACA,cAAa,MAAM;AACnB;AACA;AACA,cAAa,MAAM;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAmB,YAAY;AAC/B,sBAAqB,WAAW;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,MAAM;AACnB;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,MAAM;AACnB;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,QAAQ;AACrB;AACA,cAAa,kBAAkB;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAmB,YAAY;AAC/B,sBAAqB,WAAW;AAChC;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,MAAM;AACnB,cAAa,OAAO;AACpB,eAAc,MAAM;AACpB;AACA;AACA;AACA;AACA;AACA;;AAEA,oBAAmB,YAAY;AAC/B,sBAAqB,WAAW;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAwB,WAAW;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,MAAM;AACnB,cAAa,OAAO;AACpB,eAAc,MAAM;AACpB;AACA;AACA;AACA;AACA;AACA;;AAEA,oBAAmB,YAAY;AAC/B,sBAAqB,WAAW;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAwB,WAAW;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,MAAM;AACnB,cAAa,MAAM;AACnB,cAAa,OAAO;AACpB,eAAc,MAAM;AACpB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,eAAc,MAAM;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,oBAAmB,mBAAmB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,EAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,aAAY;AACZ;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAY;AACZ;AACA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB;AACA;AACA;AACA,cAAa,OAAO;AACpB,eAAc,MAAM;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,sBAAqB,4BAA4B;AACjD,wBAAuB,0BAA0B;;AAEjD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,cAAa,OAAO;AACpB;AACA,cAAa,MAAM;AACnB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,eAAc,QAAQ;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB;AACA,cAAa,OAAO;AACpB,eAAc,QAAQ;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA,oBAAmB,YAAY;AAC/B;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,wBAAuB,iBAAiB;AACxC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,UAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,cAAa,MAAM;AACnB,eAAc;AACd;AACA;AACA;AACA;AACA;;AAEA,oBAAmB,kBAAkB;AACrC;AACA,sBAAqB,kBAAkB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,oBAAmB,wBAAwB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAO;AACP,MAAK;;AAEL;AACA;;AAEA,EAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,aAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA,aAAY;AACZ;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,aAAY;AACZ;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,cAAa,MAAM;AACnB,cAAa,OAAO;AACpB,cAAa,MAAM;AACnB,eAAc,WAAW;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,oBAAmB,sBAAsB;AACzC;;AAEA;AACA,kCAAiC,OAAO;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,gCAA+B,GAAG,MAAM,IAAI;AAC5C;AACA,uCAAsC,GAAG;AACzC,kDAAiD,GAAG,YAAY,IAAI;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAa,MAAM;AACnB,cAAa,MAAM;AACnB,cAAa,MAAM;AACnB,cAAa,MAAM;AACnB,eAAc,WAAW;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,oBAAmB,UAAU;AAC7B;AACA;AACA,sBAAqB,UAAU;AAC/B;AACA;AACA;AACA,yCAAwC,OAAO;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,cAAa,MAAM;AACnB,cAAa,MAAM;AACnB,cAAa,MAAM;AACnB,cAAa,MAAM;AACnB,eAAc,WAAW;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,oBAAmB,qBAAqB;AACxC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,eAAc,MAAM;AACpB;AACA;AACA;AACA;AACA;AACA;AACA,sBAAqB,YAAY;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,sBAAqB,YAAY;AACjC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,EAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,aAAY;AACZ;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAY;AACZ;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,MAAM;AACnB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB;AACA,eAAc,MAAM;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,oBAAmB,gBAAgB;AACnC,sBAAqB,eAAe;AACpC;AACA;;AAEA;AACA;AACA,wBAAuB,QAAQ;AAC/B;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,eAAc;AACd;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,eAAc;AACd;AACA;AACA;AACA;AACA;AACA;;AAEA,oBAAmB,QAAQ;AAC3B;AACA;;AAEA,sBAAqB,OAAO;AAC5B;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,eAAc;AACd;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,eAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB,eAAc,MAAM;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,EAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,eAAc,OAAO;AACrB;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAa,OAAO;AACpB,eAAc,OAAO;AACrB;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,eAAc;AACd;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,eAAc;AACd;AACA;AACA;AACA;;AAEA,EAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,cAAa,MAAM;AACnB;AACA,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,SAAS;AACtB,cAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA,oBAAmB,YAAY;AAC/B,sBAAqB,WAAW;AAChC;AACA;AACA;AACA;AACA;;AAEA,EAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,EAAC;;AAED;AACA;AACA;AACA;AACA,gBAAe;AACf;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,cAAa,kBAAkB;AAC/B,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB;AACA;AACA,EAAC;;AAED;AACA;AACA;AACA;AACA,gBAAe;AACf;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA,aAAY;AACZ;AACA;AACA;;AAEA;AACA;AACA,aAAY;AACZ;AACA;AACA;;AAEA;AACA;AACA,eAAc;AACd;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAc;AACd;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAc;AACd;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,eAAc,OAAO;AACrB;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,eAAc,OAAO;AACrB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,EAAC;;AAED;AACA;AACA;AACA;AACA;AACA,cAAa,sBAAsB;AACnC,gBAAe;AACf;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,QAAO;AACP;AACA;AACA;;AAEA;;AAEA;AACA;AACA,aAAY;AACZ;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAY;AACZ;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB,cAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,cAAa,OAAO;AACpB,eAAc,SAAS;AACvB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,aAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA,aAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA,aAAY;AACZ;AACA;;;AAGA;AACA;AACA;AACA,aAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA,cAAa,eAAe;AAC5B;AACA,cAAa,OAAO;AACpB,eAAc,OAAO;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,oBAAmB,WAAW;AAC9B;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAc;AACd;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAc;AACd;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAc;AACd;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAc;AACd;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB,eAAc,MAAM;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA,cAAa,eAAe;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,oBAAmB,kBAAkB;AACrC;AACA;AACA,0BAAyB,kBAAkB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,cAAa,eAAe;AAC5B;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,cAAa,kBAAkB;AAC/B,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,MAAK;;AAEL;AACA;AACA,MAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,cAAa,kBAAkB;AAC/B,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,oBAAmB,YAAY;AAC/B,sBAAqB,WAAW;AAChC;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,4BAA2B,wBAAwB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAG;;AAEH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAG;;AAEH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAG;;;AAGH;AACA;AACA;AACA;AACA,EAAC;;AAED;AACA;AACA;AACA;AACA,cAAa,qCAAqC;AAClD;AACA,gBAAe;AACf;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAS;AACT;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,aAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA,aAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA,aAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA,aAAY;AACZ;AACA;;AAEA;AACA;AACA,eAAc;AACd;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAc;AACd;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAc;AACd;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAc;AACd;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAc;AACd;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,cAAa,kBAAkB;AAC/B,cAAa,OAAO;AACpB,cAAa,OAAO;AACpB;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,MAAK;;AAEL;AACA;AACA,MAAK;AACL;;AAEA;AACA;AACA,cAAa,oBAAoB;AACjC;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB;AACA;AACA;AACA;;AAEA;AACA;AACA,cAAa,OAAO;AACpB;AACA;AACA;AACA;;AAEA,EAAC;;;;;;;AC54ED;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,MAAK;AACL;AACA;;;;;;;ACtCA;;AAEA;AACA,yBAAwB;AACxB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,EAAC;;;AAGD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAA+C,aAAa;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA,QAAO;AACP,MAAK;AACL;AACA;AACA;AACA;AACA;AACA,MAAK;AACL;AACA;;;;;;;;AC5DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAS;AACT;AACA;AACA,IAAG;AACH;AACA;AACA","file":"index.bundle.js","sourcesContent":[" \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId])\n \t\t\treturn installedModules[moduleId].exports;\n\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\texports: {},\n \t\t\tid: moduleId,\n \t\t\tloaded: false\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.loaded = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(0);\n\n\n\n/** WEBPACK FOOTER **\n ** webpack/bootstrap b9a9c9e3da985e86b33e\n **/","/* global OT config */\n// A real app would use require('opentok-filters/src/filters.js');\nconst filters = require('../../src/filters.js');\n// A real app would use require('opentok-filters')(filters.none);\nconst filter = require('../..')(filters.none);\n\nconst selector = document.querySelector('select');\nlet f;\nfor (f of Object.keys(filters)) {\n  const option = document.createElement('option');\n  option.value = f;\n  option.innerHTML = f;\n  selector.appendChild(option);\n}\n\nselector.addEventListener('change', () => {\n  filter.change(filters[selector.value]);\n});\n\n\n// Wait for OT to load before we start using it\nwindow.addEventListener('load', () => {\n  // Simple Hello World App\n  const session = OT.initSession(config.OT_API_KEY, config.OT_SESSION_ID);\n  session.on('streamCreated', event => {\n    session.subscribe(event.stream, err => {\n      if (err) alert(err.message);\n    });\n  });\n\n  session.connect(config.OT_TOKEN, err => {\n    if (err) alert(err.message);\n    const publisher = session.publish(null, {\n      resolution: '320x240',\n    });\n    filter.setPublisher(publisher);\n  });\n});\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./src/index.js\n ** module id = 0\n ** module chunks = 1\n **/","const tracking = window.tracking = {};\nrequire('tracking/build/tracking');\nconst filterTask = require('./filterTask');\n\nfunction colourShift(r, g, b, a, imgData) {\n  const res = new Uint8ClampedArray(imgData.data.length);\n  for (let i = 0; i < imgData.data.length; i += 4) {\n    res[i] = Math.min(255, imgData.data[i] + r);\n    res[i + 1] = Math.max(0, Math.min(255, imgData.data[i + 1] + g));\n    res[i + 2] = Math.max(0, Math.min(255, imgData.data[i + 2] + b));\n    res[i + 3] = Math.max(0, Math.min(255, imgData.data[i + 3] + a));\n  }\n  const resData = new ImageData(res, imgData.width, imgData.height);\n  return resData;\n}\n\nfunction colourFilter(r, g, b, a, videoElement, canvas) {\n  return filterTask(videoElement, canvas, colourShift.bind(this, r, g, b, a));\n}\n\n// Filters take a source videoElement and a canvas. The video element contains the users\n// camera and the filter function transforms it onto the canvas element provided.\nmodule.exports = {\n  none: function none(videoElement, canvas) {\n    const filter = imgData => imgData;\n    return filterTask(videoElement, canvas, filter);\n  },\n  red: colourFilter.bind(this, 150, 0, 0, 0),\n  green: colourFilter.bind(this, 0, 150, 0, 0),\n  blue: colourFilter.bind(this, 0, 0, 150, 0),\n  grayscale: function grayscale(videoElement, canvas) {\n    const filter = imgData => {\n      const grayData = tracking.Image.grayscale(imgData.data, imgData.width, imgData.height, true);\n      return new ImageData(grayData, imgData.width, imgData.height);\n    };\n\n    return filterTask(videoElement, canvas, filter);\n  },\n  blur: function blur(videoElement, canvas) {\n    const filter = imgData => {\n      const blurData = tracking.Image.blur(imgData.data, imgData.width, imgData.height, 50);\n      return new ImageData(new Uint8ClampedArray(blurData), imgData.width, imgData.height);\n    };\n    return filterTask(videoElement, canvas, filter);\n  },\n  sketch: function sketch(videoElement, canvas) {\n    const filter = imgData => {\n      const sobelData = tracking.Image.sobel(imgData.data, imgData.width, imgData.height);\n      return new ImageData(new Uint8ClampedArray(sobelData), imgData.width, imgData.height);\n    };\n    return filterTask(videoElement, canvas, filter);\n  },\n  invert: function invert(videoElement, canvas) {\n    const filter = imgData => {\n      const res = new Uint8ClampedArray(imgData.data.length);\n      for (let i = 0; i < imgData.data.length; i += 4) {\n        res[i] = 255 - imgData.data[i];\n        res[i + 1] = 255 - imgData.data[i + 1];\n        res[i + 2] = 255 - imgData.data[i + 2];\n        res[i + 3] = imgData.data[i + 3];\n      }\n      const resData = new ImageData(res, imgData.width, imgData.height);\n      return resData;\n    };\n    return filterTask(videoElement, canvas, filter);\n  },\n  face: function face(videoElement, canvas, imageSrc) {\n    // Draw on the canvas with no filter every requestAnimationFrame\n    let tmpCanvas;\n    let tmpCtx;\n    let image;\n    let currentFaces = [];\n    let currentMessage;\n    let worker;\n\n    const createMessage = function createMessage(dataArray) {\n      return {\n        array: dataArray,\n        width: canvas.width,\n        height: canvas.height,\n      };\n    };\n\n    const filter = imgData => {\n      currentMessage = createMessage(imgData.data);\n      if (!worker) {\n        // We create a worker to detect the faces. We can't send the data\n        // for every frame so we just send the most recent frame every time the\n        // worker returns\n        worker = new Worker('./js/faceWorker.bundle.js');\n        worker.addEventListener('message', event => {\n          if (event.data.length) {\n            currentFaces = event.data;\n          } else {\n            currentFaces = [];\n          }\n          if (currentMessage) {\n            worker.postMessage(currentMessage);\n          }\n        });\n\n        worker.postMessage(currentMessage);\n      }\n\n      if (!tmpCanvas) {\n        tmpCanvas = document.createElement('canvas');\n        tmpCtx = tmpCanvas.getContext('2d');\n        tmpCanvas.width = canvas.width;\n        tmpCanvas.height = canvas.height;\n        image = document.createElement('img');\n        image.src = imageSrc ||\n          'https://aullman.github.io/opentok-camera-filters/images/comedy-glasses.png';\n      }\n      tmpCtx.putImageData(imgData, 0, 0);\n\n      currentFaces.forEach(rect => {\n        tmpCtx.drawImage(image, rect.x, rect.y, rect.width, rect.height);\n      });\n      return tmpCtx.getImageData(0, 0, tmpCanvas.width, tmpCanvas.height);\n    };\n    return filterTask(videoElement, canvas, filter);\n  },\n};\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ../src/filters.js\n ** module id = 3\n ** module chunks = 1\n **/","/**\n * tracking - A modern approach for Computer Vision on the web.\n * @author Eduardo Lundgren <edu@rdo.io>\n * @version v1.1.2\n * @link http://trackingjs.com\n * @license BSD\n */\n(function(window, undefined) {\n  window.tracking = window.tracking || {};\n\n  /**\n   * Inherit the prototype methods from one constructor into another.\n   *\n   * Usage:\n   * <pre>\n   * function ParentClass(a, b) { }\n   * ParentClass.prototype.foo = function(a) { }\n   *\n   * function ChildClass(a, b, c) {\n   *   tracking.base(this, a, b);\n   * }\n   * tracking.inherits(ChildClass, ParentClass);\n   *\n   * var child = new ChildClass('a', 'b', 'c');\n   * child.foo();\n   * </pre>\n   *\n   * @param {Function} childCtor Child class.\n   * @param {Function} parentCtor Parent class.\n   */\n  tracking.inherits = function(childCtor, parentCtor) {\n    function TempCtor() {\n    }\n    TempCtor.prototype = parentCtor.prototype;\n    childCtor.superClass_ = parentCtor.prototype;\n    childCtor.prototype = new TempCtor();\n    childCtor.prototype.constructor = childCtor;\n\n    /**\n     * Calls superclass constructor/method.\n     *\n     * This function is only available if you use tracking.inherits to express\n     * inheritance relationships between classes.\n     *\n     * @param {!object} me Should always be \"this\".\n     * @param {string} methodName The method name to call. Calling superclass\n     *     constructor can be done with the special string 'constructor'.\n     * @param {...*} var_args The arguments to pass to superclass\n     *     method/constructor.\n     * @return {*} The return value of the superclass method/constructor.\n     */\n    childCtor.base = function(me, methodName) {\n      var args = Array.prototype.slice.call(arguments, 2);\n      return parentCtor.prototype[methodName].apply(me, args);\n    };\n  };\n\n  /**\n   * Captures the user camera when tracking a video element and set its source\n   * to the camera stream.\n   * @param {HTMLVideoElement} element Canvas element to track.\n   * @param {object} opt_options Optional configuration to the tracker.\n   */\n  tracking.initUserMedia_ = function(element, opt_options) {\n    window.navigator.getUserMedia({\n      video: true,\n      audio: !!(opt_options && opt_options.audio)\n    }, function(stream) {\n        try {\n          element.src = window.URL.createObjectURL(stream);\n        } catch (err) {\n          element.src = stream;\n        }\n      }, function() {\n        throw Error('Cannot capture user camera.');\n      }\n    );\n  };\n\n  /**\n   * Tests whether the object is a dom node.\n   * @param {object} o Object to be tested.\n   * @return {boolean} True if the object is a dom node.\n   */\n  tracking.isNode = function(o) {\n    return o.nodeType || this.isWindow(o);\n  };\n\n  /**\n   * Tests whether the object is the `window` object.\n   * @param {object} o Object to be tested.\n   * @return {boolean} True if the object is the `window` object.\n   */\n  tracking.isWindow = function(o) {\n    return !!(o && o.alert && o.document);\n  };\n\n  /**\n   * Selects a dom node from a CSS3 selector using `document.querySelector`.\n   * @param {string} selector\n   * @param {object} opt_element The root element for the query. When not\n   *     specified `document` is used as root element.\n   * @return {HTMLElement} The first dom element that matches to the selector.\n   *     If not found, returns `null`.\n   */\n  tracking.one = function(selector, opt_element) {\n    if (this.isNode(selector)) {\n      return selector;\n    }\n    return (opt_element || document).querySelector(selector);\n  };\n\n  /**\n   * Tracks a canvas, image or video element based on the specified `tracker`\n   * instance. This method extract the pixel information of the input element\n   * to pass to the `tracker` instance. When tracking a video, the\n   * `tracker.track(pixels, width, height)` will be in a\n   * `requestAnimationFrame` loop in order to track all video frames.\n   *\n   * Example:\n   * var tracker = new tracking.ColorTracker();\n   *\n   * tracking.track('#video', tracker);\n   * or\n   * tracking.track('#video', tracker, { camera: true });\n   *\n   * tracker.on('track', function(event) {\n   *   // console.log(event.data[0].x, event.data[0].y)\n   * });\n   *\n   * @param {HTMLElement} element The element to track, canvas, image or\n   *     video.\n   * @param {tracking.Tracker} tracker The tracker instance used to track the\n   *     element.\n   * @param {object} opt_options Optional configuration to the tracker.\n   */\n  tracking.track = function(element, tracker, opt_options) {\n    element = tracking.one(element);\n    if (!element) {\n      throw new Error('Element not found, try a different element or selector.');\n    }\n    if (!tracker) {\n      throw new Error('Tracker not specified, try `tracking.track(element, new tracking.FaceTracker())`.');\n    }\n\n    switch (element.nodeName.toLowerCase()) {\n      case 'canvas':\n        return this.trackCanvas_(element, tracker, opt_options);\n      case 'img':\n        return this.trackImg_(element, tracker, opt_options);\n      case 'video':\n        if (opt_options) {\n          if (opt_options.camera) {\n            this.initUserMedia_(element, opt_options);\n          }\n        }\n        return this.trackVideo_(element, tracker, opt_options);\n      default:\n        throw new Error('Element not supported, try in a canvas, img, or video.');\n    }\n  };\n\n  /**\n   * Tracks a canvas element based on the specified `tracker` instance and\n   * returns a `TrackerTask` for this track.\n   * @param {HTMLCanvasElement} element Canvas element to track.\n   * @param {tracking.Tracker} tracker The tracker instance used to track the\n   *     element.\n   * @param {object} opt_options Optional configuration to the tracker.\n   * @return {tracking.TrackerTask}\n   * @private\n   */\n  tracking.trackCanvas_ = function(element, tracker) {\n    var self = this;\n    var task = new tracking.TrackerTask(tracker);\n    task.on('run', function() {\n      self.trackCanvasInternal_(element, tracker);\n    });\n    return task.run();\n  };\n\n  /**\n   * Tracks a canvas element based on the specified `tracker` instance. This\n   * method extract the pixel information of the input element to pass to the\n   * `tracker` instance.\n   * @param {HTMLCanvasElement} element Canvas element to track.\n   * @param {tracking.Tracker} tracker The tracker instance used to track the\n   *     element.\n   * @param {object} opt_options Optional configuration to the tracker.\n   * @private\n   */\n  tracking.trackCanvasInternal_ = function(element, tracker) {\n    var width = element.width;\n    var height = element.height;\n    var context = element.getContext('2d');\n    var imageData = context.getImageData(0, 0, width, height);\n    tracker.track(imageData.data, width, height);\n  };\n\n  /**\n   * Tracks a image element based on the specified `tracker` instance. This\n   * method extract the pixel information of the input element to pass to the\n   * `tracker` instance.\n   * @param {HTMLImageElement} element Canvas element to track.\n   * @param {tracking.Tracker} tracker The tracker instance used to track the\n   *     element.\n   * @param {object} opt_options Optional configuration to the tracker.\n   * @private\n   */\n  tracking.trackImg_ = function(element, tracker) {\n    var width = element.width;\n    var height = element.height;\n    var canvas = document.createElement('canvas');\n\n    canvas.width = width;\n    canvas.height = height;\n\n    var task = new tracking.TrackerTask(tracker);\n    task.on('run', function() {\n      tracking.Canvas.loadImage(canvas, element.src, 0, 0, width, height, function() {\n        tracking.trackCanvasInternal_(canvas, tracker);\n      });\n    });\n    return task.run();\n  };\n\n  /**\n   * Tracks a video element based on the specified `tracker` instance. This\n   * method extract the pixel information of the input element to pass to the\n   * `tracker` instance. The `tracker.track(pixels, width, height)` will be in\n   * a `requestAnimationFrame` loop in order to track all video frames.\n   * @param {HTMLVideoElement} element Canvas element to track.\n   * @param {tracking.Tracker} tracker The tracker instance used to track the\n   *     element.\n   * @param {object} opt_options Optional configuration to the tracker.\n   * @private\n   */\n  tracking.trackVideo_ = function(element, tracker) {\n    var canvas = document.createElement('canvas');\n    var context = canvas.getContext('2d');\n    var width;\n    var height;\n\n    var resizeCanvas_ = function() {\n      width = element.offsetWidth;\n      height = element.offsetHeight;\n      canvas.width = width;\n      canvas.height = height;\n    };\n    resizeCanvas_();\n    element.addEventListener('resize', resizeCanvas_);\n\n    var requestId;\n    var requestAnimationFrame_ = function() {\n      requestId = window.requestAnimationFrame(function() {\n        if (element.readyState === element.HAVE_ENOUGH_DATA) {\n          try {\n            // Firefox v~30.0 gets confused with the video readyState firing an\n            // erroneous HAVE_ENOUGH_DATA just before HAVE_CURRENT_DATA state,\n            // hence keep trying to read it until resolved.\n            context.drawImage(element, 0, 0, width, height);\n          } catch (err) {}\n          tracking.trackCanvasInternal_(canvas, tracker);\n        }\n        requestAnimationFrame_();\n      });\n    };\n\n    var task = new tracking.TrackerTask(tracker);\n    task.on('stop', function() {\n      window.cancelAnimationFrame(requestId);\n    });\n    task.on('run', function() {\n      requestAnimationFrame_();\n    });\n    return task.run();\n  };\n\n  // Browser polyfills\n  //===================\n\n  if (!window.URL) {\n    window.URL = window.URL || window.webkitURL || window.msURL || window.oURL;\n  }\n\n  if (!navigator.getUserMedia) {\n    navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia ||\n    navigator.mozGetUserMedia || navigator.msGetUserMedia;\n  }\n}(window));\n\n(function() {\n  /**\n   * EventEmitter utility.\n   * @constructor\n   */\n  tracking.EventEmitter = function() {};\n\n  /**\n   * Holds event listeners scoped by event type.\n   * @type {object}\n   * @private\n   */\n  tracking.EventEmitter.prototype.events_ = null;\n\n  /**\n   * Adds a listener to the end of the listeners array for the specified event.\n   * @param {string} event\n   * @param {function} listener\n   * @return {object} Returns emitter, so calls can be chained.\n   */\n  tracking.EventEmitter.prototype.addListener = function(event, listener) {\n    if (typeof listener !== 'function') {\n      throw new TypeError('Listener must be a function');\n    }\n    if (!this.events_) {\n      this.events_ = {};\n    }\n\n    this.emit('newListener', event, listener);\n\n    if (!this.events_[event]) {\n      this.events_[event] = [];\n    }\n\n    this.events_[event].push(listener);\n\n    return this;\n  };\n\n  /**\n   * Returns an array of listeners for the specified event.\n   * @param {string} event\n   * @return {array} Array of listeners.\n   */\n  tracking.EventEmitter.prototype.listeners = function(event) {\n    return this.events_ && this.events_[event];\n  };\n\n  /**\n   * Execute each of the listeners in order with the supplied arguments.\n   * @param {string} event\n   * @param {*} opt_args [arg1], [arg2], [...]\n   * @return {boolean} Returns true if event had listeners, false otherwise.\n   */\n  tracking.EventEmitter.prototype.emit = function(event) {\n    var listeners = this.listeners(event);\n    if (listeners) {\n      var args = Array.prototype.slice.call(arguments, 1);\n      for (var i = 0; i < listeners.length; i++) {\n        if (listeners[i]) {\n          listeners[i].apply(this, args);\n        }\n      }\n      return true;\n    }\n    return false;\n  };\n\n  /**\n   * Adds a listener to the end of the listeners array for the specified event.\n   * @param {string} event\n   * @param {function} listener\n   * @return {object} Returns emitter, so calls can be chained.\n   */\n  tracking.EventEmitter.prototype.on = tracking.EventEmitter.prototype.addListener;\n\n  /**\n   * Adds a one time listener for the event. This listener is invoked only the\n   * next time the event is fired, after which it is removed.\n   * @param {string} event\n   * @param {function} listener\n   * @return {object} Returns emitter, so calls can be chained.\n   */\n  tracking.EventEmitter.prototype.once = function(event, listener) {\n    var self = this;\n    self.on(event, function handlerInternal() {\n      self.removeListener(event, handlerInternal);\n      listener.apply(this, arguments);\n    });\n  };\n\n  /**\n   * Removes all listeners, or those of the specified event. It's not a good\n   * idea to remove listeners that were added elsewhere in the code,\n   * especially when it's on an emitter that you didn't create.\n   * @param {string} event\n   * @return {object} Returns emitter, so calls can be chained.\n   */\n  tracking.EventEmitter.prototype.removeAllListeners = function(opt_event) {\n    if (!this.events_) {\n      return this;\n    }\n    if (opt_event) {\n      delete this.events_[opt_event];\n    } else {\n      delete this.events_;\n    }\n    return this;\n  };\n\n  /**\n   * Remove a listener from the listener array for the specified event.\n   * Caution: changes array indices in the listener array behind the listener.\n   * @param {string} event\n   * @param {function} listener\n   * @return {object} Returns emitter, so calls can be chained.\n   */\n  tracking.EventEmitter.prototype.removeListener = function(event, listener) {\n    if (typeof listener !== 'function') {\n      throw new TypeError('Listener must be a function');\n    }\n    if (!this.events_) {\n      return this;\n    }\n\n    var listeners = this.listeners(event);\n    if (Array.isArray(listeners)) {\n      var i = listeners.indexOf(listener);\n      if (i < 0) {\n        return this;\n      }\n      listeners.splice(i, 1);\n    }\n\n    return this;\n  };\n\n  /**\n   * By default EventEmitters will print a warning if more than 10 listeners\n   * are added for a particular event. This is a useful default which helps\n   * finding memory leaks. Obviously not all Emitters should be limited to 10.\n   * This function allows that to be increased. Set to zero for unlimited.\n   * @param {number} n The maximum number of listeners.\n   */\n  tracking.EventEmitter.prototype.setMaxListeners = function() {\n    throw new Error('Not implemented');\n  };\n\n}());\n\n(function() {\n  /**\n   * Canvas utility.\n   * @static\n   * @constructor\n   */\n  tracking.Canvas = {};\n\n  /**\n   * Loads an image source into the canvas.\n   * @param {HTMLCanvasElement} canvas The canvas dom element.\n   * @param {string} src The image source.\n   * @param {number} x The canvas horizontal coordinate to load the image.\n   * @param {number} y The canvas vertical coordinate to load the image.\n   * @param {number} width The image width.\n   * @param {number} height The image height.\n   * @param {function} opt_callback Callback that fires when the image is loaded\n   *     into the canvas.\n   * @static\n   */\n  tracking.Canvas.loadImage = function(canvas, src, x, y, width, height, opt_callback) {\n    var instance = this;\n    var img = new window.Image();\n    img.crossOrigin = '*';\n    img.onload = function() {\n      var context = canvas.getContext('2d');\n      canvas.width = width;\n      canvas.height = height;\n      context.drawImage(img, x, y, width, height);\n      if (opt_callback) {\n        opt_callback.call(instance);\n      }\n      img = null;\n    };\n    img.src = src;\n  };\n}());\n\n(function() {\n  /**\n   * DisjointSet utility with path compression. Some applications involve\n   * grouping n distinct objects into a collection of disjoint sets. Two\n   * important operations are then finding which set a given object belongs to\n   * and uniting the two sets. A disjoint set data structure maintains a\n   * collection S={ S1 , S2 ,..., Sk } of disjoint dynamic sets. Each set is\n   * identified by a representative, which usually is a member in the set.\n   * @static\n   * @constructor\n   */\n  tracking.DisjointSet = function(length) {\n    if (length === undefined) {\n      throw new Error('DisjointSet length not specified.');\n    }\n    this.length = length;\n    this.parent = new Uint32Array(length);\n    for (var i = 0; i < length; i++) {\n      this.parent[i] = i;\n    }\n  };\n\n  /**\n   * Holds the length of the internal set.\n   * @type {number}\n   */\n  tracking.DisjointSet.prototype.length = null;\n\n  /**\n   * Holds the set containing the representative values.\n   * @type {Array.<number>}\n   */\n  tracking.DisjointSet.prototype.parent = null;\n\n  /**\n   * Finds a pointer to the representative of the set containing i.\n   * @param {number} i\n   * @return {number} The representative set of i.\n   */\n  tracking.DisjointSet.prototype.find = function(i) {\n    if (this.parent[i] === i) {\n      return i;\n    } else {\n      return (this.parent[i] = this.find(this.parent[i]));\n    }\n  };\n\n  /**\n   * Unites two dynamic sets containing objects i and j, say Si and Sj, into\n   * a new set that Si ∪ Sj, assuming that Si ∩ Sj = ∅;\n   * @param {number} i\n   * @param {number} j\n   */\n  tracking.DisjointSet.prototype.union = function(i, j) {\n    var iRepresentative = this.find(i);\n    var jRepresentative = this.find(j);\n    this.parent[iRepresentative] = jRepresentative;\n  };\n\n}());\n\n(function() {\n  /**\n   * Image utility.\n   * @static\n   * @constructor\n   */\n  tracking.Image = {};\n\n  /**\n   * Computes gaussian blur. Adapted from\n   * https://github.com/kig/canvasfilters.\n   * @param {pixels} pixels The pixels in a linear [r,g,b,a,...] array.\n   * @param {number} width The image width.\n   * @param {number} height The image height.\n   * @param {number} diameter Gaussian blur diameter, must be greater than 1.\n   * @return {array} The edge pixels in a linear [r,g,b,a,...] array.\n   */\n  tracking.Image.blur = function(pixels, width, height, diameter) {\n    diameter = Math.abs(diameter);\n    if (diameter <= 1) {\n      throw new Error('Diameter should be greater than 1.');\n    }\n    var radius = diameter / 2;\n    var len = Math.ceil(diameter) + (1 - (Math.ceil(diameter) % 2));\n    var weights = new Float32Array(len);\n    var rho = (radius + 0.5) / 3;\n    var rhoSq = rho * rho;\n    var gaussianFactor = 1 / Math.sqrt(2 * Math.PI * rhoSq);\n    var rhoFactor = -1 / (2 * rho * rho);\n    var wsum = 0;\n    var middle = Math.floor(len / 2);\n    for (var i = 0; i < len; i++) {\n      var x = i - middle;\n      var gx = gaussianFactor * Math.exp(x * x * rhoFactor);\n      weights[i] = gx;\n      wsum += gx;\n    }\n    for (var j = 0; j < weights.length; j++) {\n      weights[j] /= wsum;\n    }\n    return this.separableConvolve(pixels, width, height, weights, weights, false);\n  };\n\n  /**\n   * Computes the integral image for summed, squared, rotated and sobel pixels.\n   * @param {array} pixels The pixels in a linear [r,g,b,a,...] array to loop\n   *     through.\n   * @param {number} width The image width.\n   * @param {number} height The image height.\n   * @param {array} opt_integralImage Empty array of size `width * height` to\n   *     be filled with the integral image values. If not specified compute sum\n   *     values will be skipped.\n   * @param {array} opt_integralImageSquare Empty array of size `width *\n   *     height` to be filled with the integral image squared values. If not\n   *     specified compute squared values will be skipped.\n   * @param {array} opt_tiltedIntegralImage Empty array of size `width *\n   *     height` to be filled with the rotated integral image values. If not\n   *     specified compute sum values will be skipped.\n   * @param {array} opt_integralImageSobel Empty array of size `width *\n   *     height` to be filled with the integral image of sobel values. If not\n   *     specified compute sobel filtering will be skipped.\n   * @static\n   */\n  tracking.Image.computeIntegralImage = function(pixels, width, height, opt_integralImage, opt_integralImageSquare, opt_tiltedIntegralImage, opt_integralImageSobel) {\n    if (arguments.length < 4) {\n      throw new Error('You should specify at least one output array in the order: sum, square, tilted, sobel.');\n    }\n    var pixelsSobel;\n    if (opt_integralImageSobel) {\n      pixelsSobel = tracking.Image.sobel(pixels, width, height);\n    }\n    for (var i = 0; i < height; i++) {\n      for (var j = 0; j < width; j++) {\n        var w = i * width * 4 + j * 4;\n        var pixel = ~~(pixels[w] * 0.299 + pixels[w + 1] * 0.587 + pixels[w + 2] * 0.114);\n        if (opt_integralImage) {\n          this.computePixelValueSAT_(opt_integralImage, width, i, j, pixel);\n        }\n        if (opt_integralImageSquare) {\n          this.computePixelValueSAT_(opt_integralImageSquare, width, i, j, pixel * pixel);\n        }\n        if (opt_tiltedIntegralImage) {\n          var w1 = w - width * 4;\n          var pixelAbove = ~~(pixels[w1] * 0.299 + pixels[w1 + 1] * 0.587 + pixels[w1 + 2] * 0.114);\n          this.computePixelValueRSAT_(opt_tiltedIntegralImage, width, i, j, pixel, pixelAbove || 0);\n        }\n        if (opt_integralImageSobel) {\n          this.computePixelValueSAT_(opt_integralImageSobel, width, i, j, pixelsSobel[w]);\n        }\n      }\n    }\n  };\n\n  /**\n   * Helper method to compute the rotated summed area table (RSAT) by the\n   * formula:\n   *\n   * RSAT(x, y) = RSAT(x-1, y-1) + RSAT(x+1, y-1) - RSAT(x, y-2) + I(x, y) + I(x, y-1)\n   *\n   * @param {number} width The image width.\n   * @param {array} RSAT Empty array of size `width * height` to be filled with\n   *     the integral image values. If not specified compute sum values will be\n   *     skipped.\n   * @param {number} i Vertical position of the pixel to be evaluated.\n   * @param {number} j Horizontal position of the pixel to be evaluated.\n   * @param {number} pixel Pixel value to be added to the integral image.\n   * @static\n   * @private\n   */\n  tracking.Image.computePixelValueRSAT_ = function(RSAT, width, i, j, pixel, pixelAbove) {\n    var w = i * width + j;\n    RSAT[w] = (RSAT[w - width - 1] || 0) + (RSAT[w - width + 1] || 0) - (RSAT[w - width - width] || 0) + pixel + pixelAbove;\n  };\n\n  /**\n   * Helper method to compute the summed area table (SAT) by the formula:\n   *\n   * SAT(x, y) = SAT(x, y-1) + SAT(x-1, y) + I(x, y) - SAT(x-1, y-1)\n   *\n   * @param {number} width The image width.\n   * @param {array} SAT Empty array of size `width * height` to be filled with\n   *     the integral image values. If not specified compute sum values will be\n   *     skipped.\n   * @param {number} i Vertical position of the pixel to be evaluated.\n   * @param {number} j Horizontal position of the pixel to be evaluated.\n   * @param {number} pixel Pixel value to be added to the integral image.\n   * @static\n   * @private\n   */\n  tracking.Image.computePixelValueSAT_ = function(SAT, width, i, j, pixel) {\n    var w = i * width + j;\n    SAT[w] = (SAT[w - width] || 0) + (SAT[w - 1] || 0) + pixel - (SAT[w - width - 1] || 0);\n  };\n\n  /**\n   * Converts a color from a colorspace based on an RGB color model to a\n   * grayscale representation of its luminance. The coefficients represent the\n   * measured intensity perception of typical trichromat humans, in\n   * particular, human vision is most sensitive to green and least sensitive\n   * to blue.\n   * @param {pixels} pixels The pixels in a linear [r,g,b,a,...] array.\n   * @param {number} width The image width.\n   * @param {number} height The image height.\n   * @param {boolean} fillRGBA If the result should fill all RGBA values with the gray scale\n   *  values, instead of returning a single value per pixel.\n   * @param {Uint8ClampedArray} The grayscale pixels in a linear array ([p,p,p,a,...] if fillRGBA\n   *  is true and [p1, p2, p3, ...] if fillRGBA is false).\n   * @static\n   */\n  tracking.Image.grayscale = function(pixels, width, height, fillRGBA) {\n    var gray = new Uint8ClampedArray(fillRGBA ? pixels.length : pixels.length >> 2);\n    var p = 0;\n    var w = 0;\n    for (var i = 0; i < height; i++) {\n      for (var j = 0; j < width; j++) {\n        var value = pixels[w] * 0.299 + pixels[w + 1] * 0.587 + pixels[w + 2] * 0.114;\n        gray[p++] = value;\n\n        if (fillRGBA) {\n          gray[p++] = value;\n          gray[p++] = value;\n          gray[p++] = pixels[w + 3];\n        }\n\n        w += 4;\n      }\n    }\n    return gray;\n  };\n\n  /**\n   * Fast horizontal separable convolution. A point spread function (PSF) is\n   * said to be separable if it can be broken into two one-dimensional\n   * signals: a vertical and a horizontal projection. The convolution is\n   * performed by sliding the kernel over the image, generally starting at the\n   * top left corner, so as to move the kernel through all the positions where\n   * the kernel fits entirely within the boundaries of the image. Adapted from\n   * https://github.com/kig/canvasfilters.\n   * @param {pixels} pixels The pixels in a linear [r,g,b,a,...] array.\n   * @param {number} width The image width.\n   * @param {number} height The image height.\n   * @param {array} weightsVector The weighting vector, e.g [-1,0,1].\n   * @param {number} opaque\n   * @return {array} The convoluted pixels in a linear [r,g,b,a,...] array.\n   */\n  tracking.Image.horizontalConvolve = function(pixels, width, height, weightsVector, opaque) {\n    var side = weightsVector.length;\n    var halfSide = Math.floor(side / 2);\n    var output = new Float32Array(width * height * 4);\n    var alphaFac = opaque ? 1 : 0;\n\n    for (var y = 0; y < height; y++) {\n      for (var x = 0; x < width; x++) {\n        var sy = y;\n        var sx = x;\n        var offset = (y * width + x) * 4;\n        var r = 0;\n        var g = 0;\n        var b = 0;\n        var a = 0;\n        for (var cx = 0; cx < side; cx++) {\n          var scy = sy;\n          var scx = Math.min(width - 1, Math.max(0, sx + cx - halfSide));\n          var poffset = (scy * width + scx) * 4;\n          var wt = weightsVector[cx];\n          r += pixels[poffset] * wt;\n          g += pixels[poffset + 1] * wt;\n          b += pixels[poffset + 2] * wt;\n          a += pixels[poffset + 3] * wt;\n        }\n        output[offset] = r;\n        output[offset + 1] = g;\n        output[offset + 2] = b;\n        output[offset + 3] = a + alphaFac * (255 - a);\n      }\n    }\n    return output;\n  };\n\n  /**\n   * Fast vertical separable convolution. A point spread function (PSF) is\n   * said to be separable if it can be broken into two one-dimensional\n   * signals: a vertical and a horizontal projection. The convolution is\n   * performed by sliding the kernel over the image, generally starting at the\n   * top left corner, so as to move the kernel through all the positions where\n   * the kernel fits entirely within the boundaries of the image. Adapted from\n   * https://github.com/kig/canvasfilters.\n   * @param {pixels} pixels The pixels in a linear [r,g,b,a,...] array.\n   * @param {number} width The image width.\n   * @param {number} height The image height.\n   * @param {array} weightsVector The weighting vector, e.g [-1,0,1].\n   * @param {number} opaque\n   * @return {array} The convoluted pixels in a linear [r,g,b,a,...] array.\n   */\n  tracking.Image.verticalConvolve = function(pixels, width, height, weightsVector, opaque) {\n    var side = weightsVector.length;\n    var halfSide = Math.floor(side / 2);\n    var output = new Float32Array(width * height * 4);\n    var alphaFac = opaque ? 1 : 0;\n\n    for (var y = 0; y < height; y++) {\n      for (var x = 0; x < width; x++) {\n        var sy = y;\n        var sx = x;\n        var offset = (y * width + x) * 4;\n        var r = 0;\n        var g = 0;\n        var b = 0;\n        var a = 0;\n        for (var cy = 0; cy < side; cy++) {\n          var scy = Math.min(height - 1, Math.max(0, sy + cy - halfSide));\n          var scx = sx;\n          var poffset = (scy * width + scx) * 4;\n          var wt = weightsVector[cy];\n          r += pixels[poffset] * wt;\n          g += pixels[poffset + 1] * wt;\n          b += pixels[poffset + 2] * wt;\n          a += pixels[poffset + 3] * wt;\n        }\n        output[offset] = r;\n        output[offset + 1] = g;\n        output[offset + 2] = b;\n        output[offset + 3] = a + alphaFac * (255 - a);\n      }\n    }\n    return output;\n  };\n\n  /**\n   * Fast separable convolution. A point spread function (PSF) is said to be\n   * separable if it can be broken into two one-dimensional signals: a\n   * vertical and a horizontal projection. The convolution is performed by\n   * sliding the kernel over the image, generally starting at the top left\n   * corner, so as to move the kernel through all the positions where the\n   * kernel fits entirely within the boundaries of the image. Adapted from\n   * https://github.com/kig/canvasfilters.\n   * @param {pixels} pixels The pixels in a linear [r,g,b,a,...] array.\n   * @param {number} width The image width.\n   * @param {number} height The image height.\n   * @param {array} horizWeights The horizontal weighting vector, e.g [-1,0,1].\n   * @param {array} vertWeights The vertical vector, e.g [-1,0,1].\n   * @param {number} opaque\n   * @return {array} The convoluted pixels in a linear [r,g,b,a,...] array.\n   */\n  tracking.Image.separableConvolve = function(pixels, width, height, horizWeights, vertWeights, opaque) {\n    var vertical = this.verticalConvolve(pixels, width, height, vertWeights, opaque);\n    return this.horizontalConvolve(vertical, width, height, horizWeights, opaque);\n  };\n\n  /**\n   * Compute image edges using Sobel operator. Computes the vertical and\n   * horizontal gradients of the image and combines the computed images to\n   * find edges in the image. The way we implement the Sobel filter here is by\n   * first grayscaling the image, then taking the horizontal and vertical\n   * gradients and finally combining the gradient images to make up the final\n   * image. Adapted from https://github.com/kig/canvasfilters.\n   * @param {pixels} pixels The pixels in a linear [r,g,b,a,...] array.\n   * @param {number} width The image width.\n   * @param {number} height The image height.\n   * @return {array} The edge pixels in a linear [r,g,b,a,...] array.\n   */\n  tracking.Image.sobel = function(pixels, width, height) {\n    pixels = this.grayscale(pixels, width, height, true);\n    var output = new Float32Array(width * height * 4);\n    var sobelSignVector = new Float32Array([-1, 0, 1]);\n    var sobelScaleVector = new Float32Array([1, 2, 1]);\n    var vertical = this.separableConvolve(pixels, width, height, sobelSignVector, sobelScaleVector);\n    var horizontal = this.separableConvolve(pixels, width, height, sobelScaleVector, sobelSignVector);\n\n    for (var i = 0; i < output.length; i += 4) {\n      var v = vertical[i];\n      var h = horizontal[i];\n      var p = Math.sqrt(h * h + v * v);\n      output[i] = p;\n      output[i + 1] = p;\n      output[i + 2] = p;\n      output[i + 3] = 255;\n    }\n\n    return output;\n  };\n\n}());\n\n(function() {\n  /**\n   * ViolaJones utility.\n   * @static\n   * @constructor\n   */\n  tracking.ViolaJones = {};\n\n  /**\n   * Holds the minimum area of intersection that defines when a rectangle is\n   * from the same group. Often when a face is matched multiple rectangles are\n   * classified as possible rectangles to represent the face, when they\n   * intersects they are grouped as one face.\n   * @type {number}\n   * @default 0.5\n   * @static\n   */\n  tracking.ViolaJones.REGIONS_OVERLAP = 0.5;\n\n  /**\n   * Holds the HAAR cascade classifiers converted from OpenCV training.\n   * @type {array}\n   * @static\n   */\n  tracking.ViolaJones.classifiers = {};\n\n  /**\n   * Detects through the HAAR cascade data rectangles matches.\n   * @param {pixels} pixels The pixels in a linear [r,g,b,a,...] array.\n   * @param {number} width The image width.\n   * @param {number} height The image height.\n   * @param {number} initialScale The initial scale to start the block\n   *     scaling.\n   * @param {number} scaleFactor The scale factor to scale the feature block.\n   * @param {number} stepSize The block step size.\n   * @param {number} edgesDensity Percentage density edges inside the\n   *     classifier block. Value from [0.0, 1.0], defaults to 0.2. If specified\n   *     edge detection will be applied to the image to prune dead areas of the\n   *     image, this can improve significantly performance.\n   * @param {number} data The HAAR cascade data.\n   * @return {array} Found rectangles.\n   * @static\n   */\n  tracking.ViolaJones.detect = function(pixels, width, height, initialScale, scaleFactor, stepSize, edgesDensity, data) {\n    var total = 0;\n    var rects = [];\n    var integralImage = new Int32Array(width * height);\n    var integralImageSquare = new Int32Array(width * height);\n    var tiltedIntegralImage = new Int32Array(width * height);\n\n    var integralImageSobel;\n    if (edgesDensity > 0) {\n      integralImageSobel = new Int32Array(width * height);\n    }\n\n    tracking.Image.computeIntegralImage(pixels, width, height, integralImage, integralImageSquare, tiltedIntegralImage, integralImageSobel);\n\n    var minWidth = data[0];\n    var minHeight = data[1];\n    var scale = initialScale * scaleFactor;\n    var blockWidth = (scale * minWidth) | 0;\n    var blockHeight = (scale * minHeight) | 0;\n\n    while (blockWidth < width && blockHeight < height) {\n      var step = (scale * stepSize + 0.5) | 0;\n      for (var i = 0; i < (height - blockHeight); i += step) {\n        for (var j = 0; j < (width - blockWidth); j += step) {\n\n          if (edgesDensity > 0) {\n            if (this.isTriviallyExcluded(edgesDensity, integralImageSobel, i, j, width, blockWidth, blockHeight)) {\n              continue;\n            }\n          }\n\n          if (this.evalStages_(data, integralImage, integralImageSquare, tiltedIntegralImage, i, j, width, blockWidth, blockHeight, scale)) {\n            rects[total++] = {\n              width: blockWidth,\n              height: blockHeight,\n              x: j,\n              y: i\n            };\n          }\n        }\n      }\n\n      scale *= scaleFactor;\n      blockWidth = (scale * minWidth) | 0;\n      blockHeight = (scale * minHeight) | 0;\n    }\n    return this.mergeRectangles_(rects);\n  };\n\n  /**\n   * Fast check to test whether the edges density inside the block is greater\n   * than a threshold, if true it tests the stages. This can improve\n   * significantly performance.\n   * @param {number} edgesDensity Percentage density edges inside the\n   *     classifier block.\n   * @param {array} integralImageSobel The integral image of a sobel image.\n   * @param {number} i Vertical position of the pixel to be evaluated.\n   * @param {number} j Horizontal position of the pixel to be evaluated.\n   * @param {number} width The image width.\n   * @return {boolean} True whether the block at position i,j can be skipped,\n   *     false otherwise.\n   * @static\n   * @protected\n   */\n  tracking.ViolaJones.isTriviallyExcluded = function(edgesDensity, integralImageSobel, i, j, width, blockWidth, blockHeight) {\n    var wbA = i * width + j;\n    var wbB = wbA + blockWidth;\n    var wbD = wbA + blockHeight * width;\n    var wbC = wbD + blockWidth;\n    var blockEdgesDensity = (integralImageSobel[wbA] - integralImageSobel[wbB] - integralImageSobel[wbD] + integralImageSobel[wbC]) / (blockWidth * blockHeight * 255);\n    if (blockEdgesDensity < edgesDensity) {\n      return true;\n    }\n    return false;\n  };\n\n  /**\n   * Evaluates if the block size on i,j position is a valid HAAR cascade\n   * stage.\n   * @param {number} data The HAAR cascade data.\n   * @param {number} i Vertical position of the pixel to be evaluated.\n   * @param {number} j Horizontal position of the pixel to be evaluated.\n   * @param {number} width The image width.\n   * @param {number} blockSize The block size.\n   * @param {number} scale The scale factor of the block size and its original\n   *     size.\n   * @param {number} inverseArea The inverse area of the block size.\n   * @return {boolean} Whether the region passes all the stage tests.\n   * @private\n   * @static\n   */\n  tracking.ViolaJones.evalStages_ = function(data, integralImage, integralImageSquare, tiltedIntegralImage, i, j, width, blockWidth, blockHeight, scale) {\n    var inverseArea = 1.0 / (blockWidth * blockHeight);\n    var wbA = i * width + j;\n    var wbB = wbA + blockWidth;\n    var wbD = wbA + blockHeight * width;\n    var wbC = wbD + blockWidth;\n    var mean = (integralImage[wbA] - integralImage[wbB] - integralImage[wbD] + integralImage[wbC]) * inverseArea;\n    var variance = (integralImageSquare[wbA] - integralImageSquare[wbB] - integralImageSquare[wbD] + integralImageSquare[wbC]) * inverseArea - mean * mean;\n\n    var standardDeviation = 1;\n    if (variance > 0) {\n      standardDeviation = Math.sqrt(variance);\n    }\n\n    var length = data.length;\n\n    for (var w = 2; w < length; ) {\n      var stageSum = 0;\n      var stageThreshold = data[w++];\n      var nodeLength = data[w++];\n\n      while (nodeLength--) {\n        var rectsSum = 0;\n        var tilted = data[w++];\n        var rectsLength = data[w++];\n\n        for (var r = 0; r < rectsLength; r++) {\n          var rectLeft = (j + data[w++] * scale + 0.5) | 0;\n          var rectTop = (i + data[w++] * scale + 0.5) | 0;\n          var rectWidth = (data[w++] * scale + 0.5) | 0;\n          var rectHeight = (data[w++] * scale + 0.5) | 0;\n          var rectWeight = data[w++];\n\n          var w1;\n          var w2;\n          var w3;\n          var w4;\n          if (tilted) {\n            // RectSum(r) = RSAT(x-h+w, y+w+h-1) + RSAT(x, y-1) - RSAT(x-h, y+h-1) - RSAT(x+w, y+w-1)\n            w1 = (rectLeft - rectHeight + rectWidth) + (rectTop + rectWidth + rectHeight - 1) * width;\n            w2 = rectLeft + (rectTop - 1) * width;\n            w3 = (rectLeft - rectHeight) + (rectTop + rectHeight - 1) * width;\n            w4 = (rectLeft + rectWidth) + (rectTop + rectWidth - 1) * width;\n            rectsSum += (tiltedIntegralImage[w1] + tiltedIntegralImage[w2] - tiltedIntegralImage[w3] - tiltedIntegralImage[w4]) * rectWeight;\n          } else {\n            // RectSum(r) = SAT(x-1, y-1) + SAT(x+w-1, y+h-1) - SAT(x-1, y+h-1) - SAT(x+w-1, y-1)\n            w1 = rectTop * width + rectLeft;\n            w2 = w1 + rectWidth;\n            w3 = w1 + rectHeight * width;\n            w4 = w3 + rectWidth;\n            rectsSum += (integralImage[w1] - integralImage[w2] - integralImage[w3] + integralImage[w4]) * rectWeight;\n            // TODO: Review the code below to analyze performance when using it instead.\n            // w1 = (rectLeft - 1) + (rectTop - 1) * width;\n            // w2 = (rectLeft + rectWidth - 1) + (rectTop + rectHeight - 1) * width;\n            // w3 = (rectLeft - 1) + (rectTop + rectHeight - 1) * width;\n            // w4 = (rectLeft + rectWidth - 1) + (rectTop - 1) * width;\n            // rectsSum += (integralImage[w1] + integralImage[w2] - integralImage[w3] - integralImage[w4]) * rectWeight;\n          }\n        }\n\n        var nodeThreshold = data[w++];\n        var nodeLeft = data[w++];\n        var nodeRight = data[w++];\n\n        if (rectsSum * inverseArea < nodeThreshold * standardDeviation) {\n          stageSum += nodeLeft;\n        } else {\n          stageSum += nodeRight;\n        }\n      }\n\n      if (stageSum < stageThreshold) {\n        return false;\n      }\n    }\n    return true;\n  };\n\n  /**\n   * Postprocess the detected sub-windows in order to combine overlapping\n   * detections into a single detection.\n   * @param {array} rects\n   * @return {array}\n   * @private\n   * @static\n   */\n  tracking.ViolaJones.mergeRectangles_ = function(rects) {\n    var disjointSet = new tracking.DisjointSet(rects.length);\n\n    for (var i = 0; i < rects.length; i++) {\n      var r1 = rects[i];\n      for (var j = 0; j < rects.length; j++) {\n        var r2 = rects[j];\n        if (tracking.Math.intersectRect(r1.x, r1.y, r1.x + r1.width, r1.y + r1.height, r2.x, r2.y, r2.x + r2.width, r2.y + r2.height)) {\n          var x1 = Math.max(r1.x, r2.x);\n          var y1 = Math.max(r1.y, r2.y);\n          var x2 = Math.min(r1.x + r1.width, r2.x + r2.width);\n          var y2 = Math.min(r1.y + r1.height, r2.y + r2.height);\n          var overlap = (x1 - x2) * (y1 - y2);\n          var area1 = (r1.width * r1.height);\n          var area2 = (r2.width * r2.height);\n\n          if ((overlap / (area1 * (area1 / area2)) >= this.REGIONS_OVERLAP) &&\n            (overlap / (area2 * (area1 / area2)) >= this.REGIONS_OVERLAP)) {\n            disjointSet.union(i, j);\n          }\n        }\n      }\n    }\n\n    var map = {};\n    for (var k = 0; k < disjointSet.length; k++) {\n      var rep = disjointSet.find(k);\n      if (!map[rep]) {\n        map[rep] = {\n          total: 1,\n          width: rects[k].width,\n          height: rects[k].height,\n          x: rects[k].x,\n          y: rects[k].y\n        };\n        continue;\n      }\n      map[rep].total++;\n      map[rep].width += rects[k].width;\n      map[rep].height += rects[k].height;\n      map[rep].x += rects[k].x;\n      map[rep].y += rects[k].y;\n    }\n\n    var result = [];\n    Object.keys(map).forEach(function(key) {\n      var rect = map[key];\n      result.push({\n        total: rect.total,\n        width: (rect.width / rect.total + 0.5) | 0,\n        height: (rect.height / rect.total + 0.5) | 0,\n        x: (rect.x / rect.total + 0.5) | 0,\n        y: (rect.y / rect.total + 0.5) | 0\n      });\n    });\n\n    return result;\n  };\n\n}());\n\n(function() {\n  /**\n   * Brief intends for \"Binary Robust Independent Elementary Features\".This\n   * method generates a binary string for each keypoint found by an extractor\n   * method.\n   * @static\n   * @constructor\n   */\n  tracking.Brief = {};\n\n  /**\n   * The set of binary tests is defined by the nd (x,y)-location pairs\n   * uniquely chosen during the initialization. Values could vary between N =\n   * 128,256,512. N=128 yield good compromises between speed, storage\n   * efficiency, and recognition rate.\n   * @type {number}\n   */\n  tracking.Brief.N = 512;\n\n  /**\n   * Caches coordinates values of (x,y)-location pairs uniquely chosen during\n   * the initialization.\n   * @type {Object.<number, Int32Array>}\n   * @private\n   * @static\n   */\n  tracking.Brief.randomImageOffsets_ = {};\n\n  /**\n   * Caches delta values of (x,y)-location pairs uniquely chosen during\n   * the initialization.\n   * @type {Int32Array}\n   * @private\n   * @static\n   */\n  tracking.Brief.randomWindowOffsets_ = null;\n\n  /**\n   * Generates a binary string for each found keypoints extracted using an\n   * extractor method.\n   * @param {array} The grayscale pixels in a linear [p1,p2,...] array.\n   * @param {number} width The image width.\n   * @param {array} keypoints\n   * @return {Int32Array} Returns an array where for each four sequence int\n   *     values represent the descriptor binary string (128 bits) necessary\n   *     to describe the corner, e.g. [0,0,0,0, 0,0,0,0, ...].\n   * @static\n   */\n  tracking.Brief.getDescriptors = function(pixels, width, keypoints) {\n    // Optimizing divide by 32 operation using binary shift\n    // (this.N >> 5) === this.N/32.\n    var descriptors = new Int32Array((keypoints.length >> 1) * (this.N >> 5));\n    var descriptorWord = 0;\n    var offsets = this.getRandomOffsets_(width);\n    var position = 0;\n\n    for (var i = 0; i < keypoints.length; i += 2) {\n      var w = width * keypoints[i + 1] + keypoints[i];\n\n      var offsetsPosition = 0;\n      for (var j = 0, n = this.N; j < n; j++) {\n        if (pixels[offsets[offsetsPosition++] + w] < pixels[offsets[offsetsPosition++] + w]) {\n          // The bit in the position `j % 32` of descriptorWord should be set to 1. We do\n          // this by making an OR operation with a binary number that only has the bit\n          // in that position set to 1. That binary number is obtained by shifting 1 left by\n          // `j % 32` (which is the same as `j & 31` left) positions.\n          descriptorWord |= 1 << (j & 31);\n        }\n\n        // If the next j is a multiple of 32, we will need to use a new descriptor word to hold\n        // the next results.\n        if (!((j + 1) & 31)) {\n          descriptors[position++] = descriptorWord;\n          descriptorWord = 0;\n        }\n      }\n    }\n\n    return descriptors;\n  };\n\n  /**\n   * Matches sets of features {mi} and {m′j} extracted from two images taken\n   * from similar, and often successive, viewpoints. A classical procedure\n   * runs as follows. For each point {mi} in the first image, search in a\n   * region of the second image around location {mi} for point {m′j}. The\n   * search is based on the similarity of the local image windows, also known\n   * as kernel windows, centered on the points, which strongly characterizes\n   * the points when the images are sufficiently close. Once each keypoint is\n   * described with its binary string, they need to be compared with the\n   * closest matching point. Distance metric is critical to the performance of\n   * in- trusion detection systems. Thus using binary strings reduces the size\n   * of the descriptor and provides an interesting data structure that is fast\n   * to operate whose similarity can be measured by the Hamming distance.\n   * @param {array} keypoints1\n   * @param {array} descriptors1\n   * @param {array} keypoints2\n   * @param {array} descriptors2\n   * @return {Int32Array} Returns an array where the index is the corner1\n   *     index coordinate, and the value is the corresponding match index of\n   *     corner2, e.g. keypoints1=[x0,y0,x1,y1,...] and\n   *     keypoints2=[x'0,y'0,x'1,y'1,...], if x0 matches x'1 and x1 matches x'0,\n   *     the return array would be [3,0].\n   * @static\n   */\n  tracking.Brief.match = function(keypoints1, descriptors1, keypoints2, descriptors2) {\n    var len1 = keypoints1.length >> 1;\n    var len2 = keypoints2.length >> 1;\n    var matches = new Array(len1);\n\n    for (var i = 0; i < len1; i++) {\n      var min = Infinity;\n      var minj = 0;\n      for (var j = 0; j < len2; j++) {\n        var dist = 0;\n        // Optimizing divide by 32 operation using binary shift\n        // (this.N >> 5) === this.N/32.\n        for (var k = 0, n = this.N >> 5; k < n; k++) {\n          dist += tracking.Math.hammingWeight(descriptors1[i * n + k] ^ descriptors2[j * n + k]);\n        }\n        if (dist < min) {\n          min = dist;\n          minj = j;\n        }\n      }\n      matches[i] = {\n        index1: i,\n        index2: minj,\n        keypoint1: [keypoints1[2 * i], keypoints1[2 * i + 1]],\n        keypoint2: [keypoints2[2 * minj], keypoints2[2 * minj + 1]],\n        confidence: 1 - min / this.N\n      };\n    }\n\n    return matches;\n  };\n\n  /**\n   * Removes matches outliers by testing matches on both directions.\n   * @param {array} keypoints1\n   * @param {array} descriptors1\n   * @param {array} keypoints2\n   * @param {array} descriptors2\n   * @return {Int32Array} Returns an array where the index is the corner1\n   *     index coordinate, and the value is the corresponding match index of\n   *     corner2, e.g. keypoints1=[x0,y0,x1,y1,...] and\n   *     keypoints2=[x'0,y'0,x'1,y'1,...], if x0 matches x'1 and x1 matches x'0,\n   *     the return array would be [3,0].\n   * @static\n   */\n  tracking.Brief.reciprocalMatch = function(keypoints1, descriptors1, keypoints2, descriptors2) {\n    var matches = [];\n    if (keypoints1.length === 0 || keypoints2.length === 0) {\n      return matches;\n    }\n\n    var matches1 = tracking.Brief.match(keypoints1, descriptors1, keypoints2, descriptors2);\n    var matches2 = tracking.Brief.match(keypoints2, descriptors2, keypoints1, descriptors1);\n    for (var i = 0; i < matches1.length; i++) {\n      if (matches2[matches1[i].index2].index2 === i) {\n        matches.push(matches1[i]);\n      }\n    }\n    return matches;\n  };\n\n  /**\n   * Gets the coordinates values of (x,y)-location pairs uniquely chosen\n   * during the initialization.\n   * @return {array} Array with the random offset values.\n   * @private\n   */\n  tracking.Brief.getRandomOffsets_ = function(width) {\n    if (!this.randomWindowOffsets_) {\n      var windowPosition = 0;\n      var windowOffsets = new Int32Array(4 * this.N);\n      for (var i = 0; i < this.N; i++) {\n        windowOffsets[windowPosition++] = Math.round(tracking.Math.uniformRandom(-15, 16));\n        windowOffsets[windowPosition++] = Math.round(tracking.Math.uniformRandom(-15, 16));\n        windowOffsets[windowPosition++] = Math.round(tracking.Math.uniformRandom(-15, 16));\n        windowOffsets[windowPosition++] = Math.round(tracking.Math.uniformRandom(-15, 16));\n      }\n      this.randomWindowOffsets_ = windowOffsets;\n    }\n\n    if (!this.randomImageOffsets_[width]) {\n      var imagePosition = 0;\n      var imageOffsets = new Int32Array(2 * this.N);\n      for (var j = 0; j < this.N; j++) {\n        imageOffsets[imagePosition++] = this.randomWindowOffsets_[4 * j] * width + this.randomWindowOffsets_[4 * j + 1];\n        imageOffsets[imagePosition++] = this.randomWindowOffsets_[4 * j + 2] * width + this.randomWindowOffsets_[4 * j + 3];\n      }\n      this.randomImageOffsets_[width] = imageOffsets;\n    }\n\n    return this.randomImageOffsets_[width];\n  };\n}());\n\n(function() {\n  /**\n   * FAST intends for \"Features from Accelerated Segment Test\". This method\n   * performs a point segment test corner detection. The segment test\n   * criterion operates by considering a circle of sixteen pixels around the\n   * corner candidate p. The detector classifies p as a corner if there exists\n   * a set of n contiguous pixelsin the circle which are all brighter than the\n   * intensity of the candidate pixel Ip plus a threshold t, or all darker\n   * than Ip − t.\n   *\n   *       15 00 01\n   *    14          02\n   * 13                03\n   * 12       []       04\n   * 11                05\n   *    10          06\n   *       09 08 07\n   *\n   * For more reference:\n   * http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.60.3991&rep=rep1&type=pdf\n   * @static\n   * @constructor\n   */\n  tracking.Fast = {};\n\n  /**\n   * Holds the threshold to determine whether the tested pixel is brighter or\n   * darker than the corner candidate p.\n   * @type {number}\n   * @default 40\n   * @static\n   */\n  tracking.Fast.THRESHOLD = 40;\n\n  /**\n   * Caches coordinates values of the circle surrounding the pixel candidate p.\n   * @type {Object.<number, Int32Array>}\n   * @private\n   * @static\n   */\n  tracking.Fast.circles_ = {};\n\n  /**\n   * Finds corners coordinates on the graysacaled image.\n   * @param {array} The grayscale pixels in a linear [p1,p2,...] array.\n   * @param {number} width The image width.\n   * @param {number} height The image height.\n   * @param {number} threshold to determine whether the tested pixel is brighter or\n   *     darker than the corner candidate p. Default value is 40.\n   * @return {array} Array containing the coordinates of all found corners,\n   *     e.g. [x0,y0,x1,y1,...], where P(x0,y0) represents a corner coordinate.\n   * @static\n   */\n  tracking.Fast.findCorners = function(pixels, width, height, opt_threshold) {\n    var circleOffsets = this.getCircleOffsets_(width);\n    var circlePixels = new Int32Array(16);\n    var corners = [];\n\n    if (opt_threshold === undefined) {\n      opt_threshold = this.THRESHOLD;\n    }\n\n    // When looping through the image pixels, skips the first three lines from\n    // the image boundaries to constrain the surrounding circle inside the image\n    // area.\n    for (var i = 3; i < height - 3; i++) {\n      for (var j = 3; j < width - 3; j++) {\n        var w = i * width + j;\n        var p = pixels[w];\n\n        // Loops the circle offsets to read the pixel value for the sixteen\n        // surrounding pixels.\n        for (var k = 0; k < 16; k++) {\n          circlePixels[k] = pixels[w + circleOffsets[k]];\n        }\n\n        if (this.isCorner(p, circlePixels, opt_threshold)) {\n          // The pixel p is classified as a corner, as optimization increment j\n          // by the circle radius 3 to skip the neighbor pixels inside the\n          // surrounding circle. This can be removed without compromising the\n          // result.\n          corners.push(j, i);\n          j += 3;\n        }\n      }\n    }\n\n    return corners;\n  };\n\n  /**\n   * Checks if the circle pixel is brighter than the candidate pixel p by\n   * a threshold.\n   * @param {number} circlePixel The circle pixel value.\n   * @param {number} p The value of the candidate pixel p.\n   * @param {number} threshold\n   * @return {Boolean}\n   * @static\n   */\n  tracking.Fast.isBrighter = function(circlePixel, p, threshold) {\n    return circlePixel - p > threshold;\n  };\n\n  /**\n   * Checks if the circle pixel is within the corner of the candidate pixel p\n   * by a threshold.\n   * @param {number} p The value of the candidate pixel p.\n   * @param {number} circlePixel The circle pixel value.\n   * @param {number} threshold\n   * @return {Boolean}\n   * @static\n   */\n  tracking.Fast.isCorner = function(p, circlePixels, threshold) {\n    if (this.isTriviallyExcluded(circlePixels, p, threshold)) {\n      return false;\n    }\n\n    for (var x = 0; x < 16; x++) {\n      var darker = true;\n      var brighter = true;\n\n      for (var y = 0; y < 9; y++) {\n        var circlePixel = circlePixels[(x + y) & 15];\n\n        if (!this.isBrighter(p, circlePixel, threshold)) {\n          brighter = false;\n          if (darker === false) {\n            break;\n          }\n        }\n\n        if (!this.isDarker(p, circlePixel, threshold)) {\n          darker = false;\n          if (brighter === false) {\n            break;\n          }\n        }\n      }\n\n      if (brighter || darker) {\n        return true;\n      }\n    }\n\n    return false;\n  };\n\n  /**\n   * Checks if the circle pixel is darker than the candidate pixel p by\n   * a threshold.\n   * @param {number} circlePixel The circle pixel value.\n   * @param {number} p The value of the candidate pixel p.\n   * @param {number} threshold\n   * @return {Boolean}\n   * @static\n   */\n  tracking.Fast.isDarker = function(circlePixel, p, threshold) {\n    return p - circlePixel > threshold;\n  };\n\n  /**\n   * Fast check to test if the candidate pixel is a trivially excluded value.\n   * In order to be a corner, the candidate pixel value should be darker or\n   * brighter than 9-12 surrounding pixels, when at least three of the top,\n   * bottom, left and right pixels are brighter or darker it can be\n   * automatically excluded improving the performance.\n   * @param {number} circlePixel The circle pixel value.\n   * @param {number} p The value of the candidate pixel p.\n   * @param {number} threshold\n   * @return {Boolean}\n   * @static\n   * @protected\n   */\n  tracking.Fast.isTriviallyExcluded = function(circlePixels, p, threshold) {\n    var count = 0;\n    var circleBottom = circlePixels[8];\n    var circleLeft = circlePixels[12];\n    var circleRight = circlePixels[4];\n    var circleTop = circlePixels[0];\n\n    if (this.isBrighter(circleTop, p, threshold)) {\n      count++;\n    }\n    if (this.isBrighter(circleRight, p, threshold)) {\n      count++;\n    }\n    if (this.isBrighter(circleBottom, p, threshold)) {\n      count++;\n    }\n    if (this.isBrighter(circleLeft, p, threshold)) {\n      count++;\n    }\n\n    if (count < 3) {\n      count = 0;\n      if (this.isDarker(circleTop, p, threshold)) {\n        count++;\n      }\n      if (this.isDarker(circleRight, p, threshold)) {\n        count++;\n      }\n      if (this.isDarker(circleBottom, p, threshold)) {\n        count++;\n      }\n      if (this.isDarker(circleLeft, p, threshold)) {\n        count++;\n      }\n      if (count < 3) {\n        return true;\n      }\n    }\n\n    return false;\n  };\n\n  /**\n   * Gets the sixteen offset values of the circle surrounding pixel.\n   * @param {number} width The image width.\n   * @return {array} Array with the sixteen offset values of the circle\n   *     surrounding pixel.\n   * @private\n   */\n  tracking.Fast.getCircleOffsets_ = function(width) {\n    if (this.circles_[width]) {\n      return this.circles_[width];\n    }\n\n    var circle = new Int32Array(16);\n\n    circle[0] = -width - width - width;\n    circle[1] = circle[0] + 1;\n    circle[2] = circle[1] + width + 1;\n    circle[3] = circle[2] + width + 1;\n    circle[4] = circle[3] + width;\n    circle[5] = circle[4] + width;\n    circle[6] = circle[5] + width - 1;\n    circle[7] = circle[6] + width - 1;\n    circle[8] = circle[7] - 1;\n    circle[9] = circle[8] - 1;\n    circle[10] = circle[9] - width - 1;\n    circle[11] = circle[10] - width - 1;\n    circle[12] = circle[11] - width;\n    circle[13] = circle[12] - width;\n    circle[14] = circle[13] - width + 1;\n    circle[15] = circle[14] - width + 1;\n\n    this.circles_[width] = circle;\n    return circle;\n  };\n}());\n\n(function() {\n  /**\n   * Math utility.\n   * @static\n   * @constructor\n   */\n  tracking.Math = {};\n\n  /**\n   * Euclidean distance between two points P(x0, y0) and P(x1, y1).\n   * @param {number} x0 Horizontal coordinate of P0.\n   * @param {number} y0 Vertical coordinate of P0.\n   * @param {number} x1 Horizontal coordinate of P1.\n   * @param {number} y1 Vertical coordinate of P1.\n   * @return {number} The euclidean distance.\n   */\n  tracking.Math.distance = function(x0, y0, x1, y1) {\n    var dx = x1 - x0;\n    var dy = y1 - y0;\n\n    return Math.sqrt(dx * dx + dy * dy);\n  };\n\n  /**\n   * Calculates the Hamming weight of a string, which is the number of symbols that are\n   * different from the zero-symbol of the alphabet used. It is thus\n   * equivalent to the Hamming distance from the all-zero string of the same\n   * length. For the most typical case, a string of bits, this is the number\n   * of 1's in the string.\n   *\n   * Example:\n   *\n   * <pre>\n   *  Binary string     Hamming weight\n   *   11101                 4\n   *   11101010              5\n   * </pre>\n   *\n   * @param {number} i Number that holds the binary string to extract the hamming weight.\n   * @return {number} The hamming weight.\n   */\n  tracking.Math.hammingWeight = function(i) {\n    i = i - ((i >> 1) & 0x55555555);\n    i = (i & 0x33333333) + ((i >> 2) & 0x33333333);\n\n    return ((i + (i >> 4) & 0xF0F0F0F) * 0x1010101) >> 24;\n  };\n\n  /**\n   * Generates a random number between [a, b] interval.\n   * @param {number} a\n   * @param {number} b\n   * @return {number}\n   */\n  tracking.Math.uniformRandom = function(a, b) {\n    return a + Math.random() * (b - a);\n  };\n\n  /**\n   * Tests if a rectangle intersects with another.\n   *\n   *  <pre>\n   *  x0y0 --------       x2y2 --------\n   *      |       |           |       |\n   *      -------- x1y1       -------- x3y3\n   * </pre>\n   *\n   * @param {number} x0 Horizontal coordinate of P0.\n   * @param {number} y0 Vertical coordinate of P0.\n   * @param {number} x1 Horizontal coordinate of P1.\n   * @param {number} y1 Vertical coordinate of P1.\n   * @param {number} x2 Horizontal coordinate of P2.\n   * @param {number} y2 Vertical coordinate of P2.\n   * @param {number} x3 Horizontal coordinate of P3.\n   * @param {number} y3 Vertical coordinate of P3.\n   * @return {boolean}\n   */\n  tracking.Math.intersectRect = function(x0, y0, x1, y1, x2, y2, x3, y3) {\n    return !(x2 > x1 || x3 < x0 || y2 > y1 || y3 < y0);\n  };\n\n}());\n\n(function() {\n  /**\n   * Matrix utility.\n   * @static\n   * @constructor\n   */\n  tracking.Matrix = {};\n\n  /**\n   * Loops the array organized as major-row order and executes `fn` callback\n   * for each iteration. The `fn` callback receives the following parameters:\n   * `(r,g,b,a,index,i,j)`, where `r,g,b,a` represents the pixel color with\n   * alpha channel, `index` represents the position in the major-row order\n   * array and `i,j` the respective indexes positions in two dimensions.\n   * @param {array} pixels The pixels in a linear [r,g,b,a,...] array to loop\n   *     through.\n   * @param {number} width The image width.\n   * @param {number} height The image height.\n   * @param {function} fn The callback function for each pixel.\n   * @param {number} opt_jump Optional jump for the iteration, by default it\n   *     is 1, hence loops all the pixels of the array.\n   * @static\n   */\n  tracking.Matrix.forEach = function(pixels, width, height, fn, opt_jump) {\n    opt_jump = opt_jump || 1;\n    for (var i = 0; i < height; i += opt_jump) {\n      for (var j = 0; j < width; j += opt_jump) {\n        var w = i * width * 4 + j * 4;\n        fn.call(this, pixels[w], pixels[w + 1], pixels[w + 2], pixels[w + 3], w, i, j);\n      }\n    }\n  };\n\n}());\n\n(function() {\n  /**\n   * EPnp utility.\n   * @static\n   * @constructor\n   */\n  tracking.EPnP = {};\n\n  tracking.EPnP.solve = function(objectPoints, imagePoints, cameraMatrix) {};\n}());\n\n(function() {\n  /**\n   * Tracker utility.\n   * @constructor\n   * @extends {tracking.EventEmitter}\n   */\n  tracking.Tracker = function() {\n    tracking.Tracker.base(this, 'constructor');\n  };\n\n  tracking.inherits(tracking.Tracker, tracking.EventEmitter);\n\n  /**\n   * Tracks the pixels on the array. This method is called for each video\n   * frame in order to emit `track` event.\n   * @param {Uint8ClampedArray} pixels The pixels data to track.\n   * @param {number} width The pixels canvas width.\n   * @param {number} height The pixels canvas height.\n   */\n  tracking.Tracker.prototype.track = function() {};\n}());\n\n(function() {\n  /**\n   * TrackerTask utility.\n   * @constructor\n   * @extends {tracking.EventEmitter}\n   */\n  tracking.TrackerTask = function(tracker) {\n    tracking.TrackerTask.base(this, 'constructor');\n\n    if (!tracker) {\n      throw new Error('Tracker instance not specified.');\n    }\n\n    this.setTracker(tracker);\n  };\n\n  tracking.inherits(tracking.TrackerTask, tracking.EventEmitter);\n\n  /**\n   * Holds the tracker instance managed by this task.\n   * @type {tracking.Tracker}\n   * @private\n   */\n  tracking.TrackerTask.prototype.tracker_ = null;\n\n  /**\n   * Holds if the tracker task is in running.\n   * @type {boolean}\n   * @private\n   */\n  tracking.TrackerTask.prototype.running_ = false;\n\n  /**\n   * Gets the tracker instance managed by this task.\n   * @return {tracking.Tracker}\n   */\n  tracking.TrackerTask.prototype.getTracker = function() {\n    return this.tracker_;\n  };\n\n  /**\n   * Returns true if the tracker task is in running, false otherwise.\n   * @return {boolean}\n   * @private\n   */\n  tracking.TrackerTask.prototype.inRunning = function() {\n    return this.running_;\n  };\n\n  /**\n   * Sets if the tracker task is in running.\n   * @param {boolean} running\n   * @private\n   */\n  tracking.TrackerTask.prototype.setRunning = function(running) {\n    this.running_ = running;\n  };\n\n  /**\n   * Sets the tracker instance managed by this task.\n   * @return {tracking.Tracker}\n   */\n  tracking.TrackerTask.prototype.setTracker = function(tracker) {\n    this.tracker_ = tracker;\n  };\n\n  /**\n   * Emits a `run` event on the tracker task for the implementers to run any\n   * child action, e.g. `requestAnimationFrame`.\n   * @return {object} Returns itself, so calls can be chained.\n   */\n  tracking.TrackerTask.prototype.run = function() {\n    var self = this;\n\n    if (this.inRunning()) {\n      return;\n    }\n\n    this.setRunning(true);\n    this.reemitTrackEvent_ = function(event) {\n      self.emit('track', event);\n    };\n    this.tracker_.on('track', this.reemitTrackEvent_);\n    this.emit('run');\n    return this;\n  };\n\n  /**\n   * Emits a `stop` event on the tracker task for the implementers to stop any\n   * child action being done, e.g. `requestAnimationFrame`.\n   * @return {object} Returns itself, so calls can be chained.\n   */\n  tracking.TrackerTask.prototype.stop = function() {\n    if (!this.inRunning()) {\n      return;\n    }\n\n    this.setRunning(false);\n    this.emit('stop');\n    this.tracker_.removeListener('track', this.reemitTrackEvent_);\n    return this;\n  };\n}());\n\n(function() {\n  /**\n   * ColorTracker utility to track colored blobs in a frame using color\n   * difference evaluation.\n   * @constructor\n   * @param {string|Array.<string>} opt_colors Optional colors to track.\n   * @extends {tracking.Tracker}\n   */\n  tracking.ColorTracker = function(opt_colors) {\n    tracking.ColorTracker.base(this, 'constructor');\n\n    if (typeof opt_colors === 'string') {\n      opt_colors = [opt_colors];\n    }\n\n    if (opt_colors) {\n      opt_colors.forEach(function(color) {\n        if (!tracking.ColorTracker.getColor(color)) {\n          throw new Error('Color not valid, try `new tracking.ColorTracker(\"magenta\")`.');\n        }\n      });\n      this.setColors(opt_colors);\n    }\n  };\n\n  tracking.inherits(tracking.ColorTracker, tracking.Tracker);\n\n  /**\n   * Holds the known colors.\n   * @type {Object.<string, function>}\n   * @private\n   * @static\n   */\n  tracking.ColorTracker.knownColors_ = {};\n\n  /**\n   * Caches coordinates values of the neighbours surrounding a pixel.\n   * @type {Object.<number, Int32Array>}\n   * @private\n   * @static\n   */\n  tracking.ColorTracker.neighbours_ = {};\n\n  /**\n   * Registers a color as known color.\n   * @param {string} name The color name.\n   * @param {function} fn The color function to test if the passed (r,g,b) is\n   *     the desired color.\n   * @static\n   */\n  tracking.ColorTracker.registerColor = function(name, fn) {\n    tracking.ColorTracker.knownColors_[name] = fn;\n  };\n\n  /**\n   * Gets the known color function that is able to test whether an (r,g,b) is\n   * the desired color.\n   * @param {string} name The color name.\n   * @return {function} The known color test function.\n   * @static\n   */\n  tracking.ColorTracker.getColor = function(name) {\n    return tracking.ColorTracker.knownColors_[name];\n  };\n\n  /**\n   * Holds the colors to be tracked by the `ColorTracker` instance.\n   * @default ['magenta']\n   * @type {Array.<string>}\n   */\n  tracking.ColorTracker.prototype.colors = ['magenta'];\n\n  /**\n   * Holds the minimum dimension to classify a rectangle.\n   * @default 20\n   * @type {number}\n   */\n  tracking.ColorTracker.prototype.minDimension = 20;\n\n  /**\n   * Holds the maximum dimension to classify a rectangle.\n   * @default Infinity\n   * @type {number}\n   */\n  tracking.ColorTracker.prototype.maxDimension = Infinity;\n\n\n  /**\n   * Holds the minimum group size to be classified as a rectangle.\n   * @default 30\n   * @type {number}\n   */\n  tracking.ColorTracker.prototype.minGroupSize = 30;\n\n  /**\n   * Calculates the central coordinate from the cloud points. The cloud points\n   * are all points that matches the desired color.\n   * @param {Array.<number>} cloud Major row order array containing all the\n   *     points from the desired color, e.g. [x1, y1, c2, y2, ...].\n   * @param {number} total Total numbers of pixels of the desired color.\n   * @return {object} Object containing the x, y and estimated z coordinate of\n   *     the blog extracted from the cloud points.\n   * @private\n   */\n  tracking.ColorTracker.prototype.calculateDimensions_ = function(cloud, total) {\n    var maxx = -1;\n    var maxy = -1;\n    var minx = Infinity;\n    var miny = Infinity;\n\n    for (var c = 0; c < total; c += 2) {\n      var x = cloud[c];\n      var y = cloud[c + 1];\n\n      if (x < minx) {\n        minx = x;\n      }\n      if (x > maxx) {\n        maxx = x;\n      }\n      if (y < miny) {\n        miny = y;\n      }\n      if (y > maxy) {\n        maxy = y;\n      }\n    }\n\n    return {\n      width: maxx - minx,\n      height: maxy - miny,\n      x: minx,\n      y: miny\n    };\n  };\n\n  /**\n   * Gets the colors being tracked by the `ColorTracker` instance.\n   * @return {Array.<string>}\n   */\n  tracking.ColorTracker.prototype.getColors = function() {\n    return this.colors;\n  };\n\n  /**\n   * Gets the minimum dimension to classify a rectangle.\n   * @return {number}\n   */\n  tracking.ColorTracker.prototype.getMinDimension = function() {\n    return this.minDimension;\n  };\n\n  /**\n   * Gets the maximum dimension to classify a rectangle.\n   * @return {number}\n   */\n  tracking.ColorTracker.prototype.getMaxDimension = function() {\n    return this.maxDimension;\n  };\n\n  /**\n   * Gets the minimum group size to be classified as a rectangle.\n   * @return {number}\n   */\n  tracking.ColorTracker.prototype.getMinGroupSize = function() {\n    return this.minGroupSize;\n  };\n\n  /**\n   * Gets the eight offset values of the neighbours surrounding a pixel.\n   * @param {number} width The image width.\n   * @return {array} Array with the eight offset values of the neighbours\n   *     surrounding a pixel.\n   * @private\n   */\n  tracking.ColorTracker.prototype.getNeighboursForWidth_ = function(width) {\n    if (tracking.ColorTracker.neighbours_[width]) {\n      return tracking.ColorTracker.neighbours_[width];\n    }\n\n    var neighbours = new Int32Array(8);\n\n    neighbours[0] = -width * 4;\n    neighbours[1] = -width * 4 + 4;\n    neighbours[2] = 4;\n    neighbours[3] = width * 4 + 4;\n    neighbours[4] = width * 4;\n    neighbours[5] = width * 4 - 4;\n    neighbours[6] = -4;\n    neighbours[7] = -width * 4 - 4;\n\n    tracking.ColorTracker.neighbours_[width] = neighbours;\n\n    return neighbours;\n  };\n\n  /**\n   * Unites groups whose bounding box intersect with each other.\n   * @param {Array.<Object>} rects\n   * @private\n   */\n  tracking.ColorTracker.prototype.mergeRectangles_ = function(rects) {\n    var intersects;\n    var results = [];\n    var minDimension = this.getMinDimension();\n    var maxDimension = this.getMaxDimension();\n\n    for (var r = 0; r < rects.length; r++) {\n      var r1 = rects[r];\n      intersects = true;\n      for (var s = r + 1; s < rects.length; s++) {\n        var r2 = rects[s];\n        if (tracking.Math.intersectRect(r1.x, r1.y, r1.x + r1.width, r1.y + r1.height, r2.x, r2.y, r2.x + r2.width, r2.y + r2.height)) {\n          intersects = false;\n          var x1 = Math.min(r1.x, r2.x);\n          var y1 = Math.min(r1.y, r2.y);\n          var x2 = Math.max(r1.x + r1.width, r2.x + r2.width);\n          var y2 = Math.max(r1.y + r1.height, r2.y + r2.height);\n          r2.height = y2 - y1;\n          r2.width = x2 - x1;\n          r2.x = x1;\n          r2.y = y1;\n          break;\n        }\n      }\n\n      if (intersects) {\n        if (r1.width >= minDimension && r1.height >= minDimension) {\n          if (r1.width <= maxDimension && r1.height <= maxDimension) {\n            results.push(r1);\n          }\n        }\n      }\n    }\n\n    return results;\n  };\n\n  /**\n   * Sets the colors to be tracked by the `ColorTracker` instance.\n   * @param {Array.<string>} colors\n   */\n  tracking.ColorTracker.prototype.setColors = function(colors) {\n    this.colors = colors;\n  };\n\n  /**\n   * Sets the minimum dimension to classify a rectangle.\n   * @param {number} minDimension\n   */\n  tracking.ColorTracker.prototype.setMinDimension = function(minDimension) {\n    this.minDimension = minDimension;\n  };\n\n  /**\n   * Sets the maximum dimension to classify a rectangle.\n   * @param {number} maxDimension\n   */\n  tracking.ColorTracker.prototype.setMaxDimension = function(maxDimension) {\n    this.maxDimension = maxDimension;\n  };\n\n  /**\n   * Sets the minimum group size to be classified as a rectangle.\n   * @param {number} minGroupSize\n   */\n  tracking.ColorTracker.prototype.setMinGroupSize = function(minGroupSize) {\n    this.minGroupSize = minGroupSize;\n  };\n\n  /**\n   * Tracks the `Video` frames. This method is called for each video frame in\n   * order to emit `track` event.\n   * @param {Uint8ClampedArray} pixels The pixels data to track.\n   * @param {number} width The pixels canvas width.\n   * @param {number} height The pixels canvas height.\n   */\n  tracking.ColorTracker.prototype.track = function(pixels, width, height) {\n    var self = this;\n    var colors = this.getColors();\n\n    if (!colors) {\n      throw new Error('Colors not specified, try `new tracking.ColorTracker(\"magenta\")`.');\n    }\n\n    var results = [];\n\n    colors.forEach(function(color) {\n      results = results.concat(self.trackColor_(pixels, width, height, color));\n    });\n\n    this.emit('track', {\n      data: results\n    });\n  };\n\n  /**\n   * Find the given color in the given matrix of pixels using Flood fill\n   * algorithm to determines the area connected to a given node in a\n   * multi-dimensional array.\n   * @param {Uint8ClampedArray} pixels The pixels data to track.\n   * @param {number} width The pixels canvas width.\n   * @param {number} height The pixels canvas height.\n   * @param {string} color The color to be found\n   * @private\n   */\n  tracking.ColorTracker.prototype.trackColor_ = function(pixels, width, height, color) {\n    var colorFn = tracking.ColorTracker.knownColors_[color];\n    var currGroup = new Int32Array(pixels.length >> 2);\n    var currGroupSize;\n    var currI;\n    var currJ;\n    var currW;\n    var marked = new Int8Array(pixels.length);\n    var minGroupSize = this.getMinGroupSize();\n    var neighboursW = this.getNeighboursForWidth_(width);\n    var queue = new Int32Array(pixels.length);\n    var queuePosition;\n    var results = [];\n    var w = -4;\n\n    if (!colorFn) {\n      return results;\n    }\n\n    for (var i = 0; i < height; i++) {\n      for (var j = 0; j < width; j++) {\n        w += 4;\n\n        if (marked[w]) {\n          continue;\n        }\n\n        currGroupSize = 0;\n\n        queuePosition = -1;\n        queue[++queuePosition] = w;\n        queue[++queuePosition] = i;\n        queue[++queuePosition] = j;\n\n        marked[w] = 1;\n\n        while (queuePosition >= 0) {\n          currJ = queue[queuePosition--];\n          currI = queue[queuePosition--];\n          currW = queue[queuePosition--];\n\n          if (colorFn(pixels[currW], pixels[currW + 1], pixels[currW + 2], pixels[currW + 3], currW, currI, currJ)) {\n            currGroup[currGroupSize++] = currJ;\n            currGroup[currGroupSize++] = currI;\n\n            for (var k = 0; k < neighboursW.length; k++) {\n              var otherW = currW + neighboursW[k];\n              var otherI = currI + neighboursI[k];\n              var otherJ = currJ + neighboursJ[k];\n              if (!marked[otherW] && otherI >= 0 && otherI < height && otherJ >= 0 && otherJ < width) {\n                queue[++queuePosition] = otherW;\n                queue[++queuePosition] = otherI;\n                queue[++queuePosition] = otherJ;\n\n                marked[otherW] = 1;\n              }\n            }\n          }\n        }\n\n        if (currGroupSize >= minGroupSize) {\n          var data = this.calculateDimensions_(currGroup, currGroupSize);\n          if (data) {\n            data.color = color;\n            results.push(data);\n          }\n        }\n      }\n    }\n\n    return this.mergeRectangles_(results);\n  };\n\n  // Default colors\n  //===================\n\n  tracking.ColorTracker.registerColor('cyan', function(r, g, b) {\n    var thresholdGreen = 50,\n      thresholdBlue = 70,\n      dx = r - 0,\n      dy = g - 255,\n      dz = b - 255;\n\n    if ((g - r) >= thresholdGreen && (b - r) >= thresholdBlue) {\n      return true;\n    }\n    return dx * dx + dy * dy + dz * dz < 6400;\n  });\n\n  tracking.ColorTracker.registerColor('magenta', function(r, g, b) {\n    var threshold = 50,\n      dx = r - 255,\n      dy = g - 0,\n      dz = b - 255;\n\n    if ((r - g) >= threshold && (b - g) >= threshold) {\n      return true;\n    }\n    return dx * dx + dy * dy + dz * dz < 19600;\n  });\n\n  tracking.ColorTracker.registerColor('yellow', function(r, g, b) {\n    var threshold = 50,\n      dx = r - 255,\n      dy = g - 255,\n      dz = b - 0;\n\n    if ((r - b) >= threshold && (g - b) >= threshold) {\n      return true;\n    }\n    return dx * dx + dy * dy + dz * dz < 10000;\n  });\n\n\n  // Caching neighbour i/j offset values.\n  //=====================================\n  var neighboursI = new Int32Array([-1, -1, 0, 1, 1, 1, 0, -1]);\n  var neighboursJ = new Int32Array([0, 1, 1, 1, 0, -1, -1, -1]);\n}());\n\n(function() {\n  /**\n   * ObjectTracker utility.\n   * @constructor\n   * @param {string|Array.<string|Array.<number>>} opt_classifiers Optional\n   *     object classifiers to track.\n   * @extends {tracking.Tracker}\n   */\n  tracking.ObjectTracker = function(opt_classifiers) {\n    tracking.ObjectTracker.base(this, 'constructor');\n\n    if (opt_classifiers) {\n      if (!Array.isArray(opt_classifiers)) {\n        opt_classifiers = [opt_classifiers];\n      }\n\n      if (Array.isArray(opt_classifiers)) {\n        opt_classifiers.forEach(function(classifier, i) {\n          if (typeof classifier === 'string') {\n            opt_classifiers[i] = tracking.ViolaJones.classifiers[classifier];\n          }\n          if (!opt_classifiers[i]) {\n            throw new Error('Object classifier not valid, try `new tracking.ObjectTracker(\"face\")`.');\n          }\n        });\n      }\n    }\n\n    this.setClassifiers(opt_classifiers);\n  };\n\n  tracking.inherits(tracking.ObjectTracker, tracking.Tracker);\n\n  /**\n   * Specifies the edges density of a block in order to decide whether to skip\n   * it or not.\n   * @default 0.2\n   * @type {number}\n   */\n  tracking.ObjectTracker.prototype.edgesDensity = 0.2;\n\n  /**\n   * Specifies the initial scale to start the feature block scaling.\n   * @default 1.0\n   * @type {number}\n   */\n  tracking.ObjectTracker.prototype.initialScale = 1.0;\n\n  /**\n   * Specifies the scale factor to scale the feature block.\n   * @default 1.25\n   * @type {number}\n   */\n  tracking.ObjectTracker.prototype.scaleFactor = 1.25;\n\n  /**\n   * Specifies the block step size.\n   * @default 1.5\n   * @type {number}\n   */\n  tracking.ObjectTracker.prototype.stepSize = 1.5;\n\n  /**\n   * Gets the tracker HAAR classifiers.\n   * @return {TypedArray.<number>}\n   */\n  tracking.ObjectTracker.prototype.getClassifiers = function() {\n    return this.classifiers;\n  };\n\n  /**\n   * Gets the edges density value.\n   * @return {number}\n   */\n  tracking.ObjectTracker.prototype.getEdgesDensity = function() {\n    return this.edgesDensity;\n  };\n\n  /**\n   * Gets the initial scale to start the feature block scaling.\n   * @return {number}\n   */\n  tracking.ObjectTracker.prototype.getInitialScale = function() {\n    return this.initialScale;\n  };\n\n  /**\n   * Gets the scale factor to scale the feature block.\n   * @return {number}\n   */\n  tracking.ObjectTracker.prototype.getScaleFactor = function() {\n    return this.scaleFactor;\n  };\n\n  /**\n   * Gets the block step size.\n   * @return {number}\n   */\n  tracking.ObjectTracker.prototype.getStepSize = function() {\n    return this.stepSize;\n  };\n\n  /**\n   * Tracks the `Video` frames. This method is called for each video frame in\n   * order to emit `track` event.\n   * @param {Uint8ClampedArray} pixels The pixels data to track.\n   * @param {number} width The pixels canvas width.\n   * @param {number} height The pixels canvas height.\n   */\n  tracking.ObjectTracker.prototype.track = function(pixels, width, height) {\n    var self = this;\n    var classifiers = this.getClassifiers();\n\n    if (!classifiers) {\n      throw new Error('Object classifier not specified, try `new tracking.ObjectTracker(\"face\")`.');\n    }\n\n    var results = [];\n\n    classifiers.forEach(function(classifier) {\n      results = results.concat(tracking.ViolaJones.detect(pixels, width, height, self.getInitialScale(), self.getScaleFactor(), self.getStepSize(), self.getEdgesDensity(), classifier));\n    });\n\n    this.emit('track', {\n      data: results\n    });\n  };\n\n  /**\n   * Sets the tracker HAAR classifiers.\n   * @param {TypedArray.<number>} classifiers\n   */\n  tracking.ObjectTracker.prototype.setClassifiers = function(classifiers) {\n    this.classifiers = classifiers;\n  };\n\n  /**\n   * Sets the edges density.\n   * @param {number} edgesDensity\n   */\n  tracking.ObjectTracker.prototype.setEdgesDensity = function(edgesDensity) {\n    this.edgesDensity = edgesDensity;\n  };\n\n  /**\n   * Sets the initial scale to start the block scaling.\n   * @param {number} initialScale\n   */\n  tracking.ObjectTracker.prototype.setInitialScale = function(initialScale) {\n    this.initialScale = initialScale;\n  };\n\n  /**\n   * Sets the scale factor to scale the feature block.\n   * @param {number} scaleFactor\n   */\n  tracking.ObjectTracker.prototype.setScaleFactor = function(scaleFactor) {\n    this.scaleFactor = scaleFactor;\n  };\n\n  /**\n   * Sets the block step size.\n   * @param {number} stepSize\n   */\n  tracking.ObjectTracker.prototype.setStepSize = function(stepSize) {\n    this.stepSize = stepSize;\n  };\n\n}());\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ../~/tracking/build/tracking.js\n ** module id = 4\n ** module chunks = 1\n **/","module.exports = function filterTask(videoElement, canvas, selectedFilter) {\n  let tmpCanvas;\n  let tmpCtx;\n  let ctx;\n  let stopped = false;\n\n  // Draws a frame on the specified canvas after applying the selected filter every\n  // requestAnimationFrame\n  const drawFrame = function drawFrame() {\n    if (!ctx) {\n      ctx = canvas.getContext('2d');\n    }\n    if (!tmpCanvas) {\n      tmpCanvas = document.createElement('canvas');\n      tmpCtx = tmpCanvas.getContext('2d');\n      tmpCanvas.width = canvas.width;\n      tmpCanvas.height = canvas.height;\n    }\n    tmpCtx.drawImage(videoElement, 0, 0, tmpCanvas.width, tmpCanvas.height);\n    const imgData = tmpCtx.getImageData(0, 0, tmpCanvas.width, tmpCanvas.height);\n    const data = selectedFilter(imgData);\n    ctx.putImageData(data, 0, 0);\n    if (!stopped) {\n      requestAnimationFrame(drawFrame);\n    } else {\n      tmpCanvas = null;\n      tmpCtx = null;\n      ctx = null;\n    }\n  };\n\n  requestAnimationFrame(drawFrame);\n\n  return {\n    stop: () => {\n      stopped = true;\n    },\n  };\n};\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ../src/filterTask.js\n ** module id = 5\n ** module chunks = 1\n **/","const mockGetUserMedia = require('./mock-get-user-media');\n\nconst canvas = document.createElement('canvas');\ncanvas.getContext('2d');  // Necessary or Firefox complains\nlet videoElement;\nlet videoElementLoaded = false;\nlet selectedFilter;\nlet initialFilter;\n\n// Mock out getUserMedia and replace the stream with the canvas.captureStream()\nmockGetUserMedia(stream => {\n  videoElement = document.createElement('video');\n  videoElement.muted = 'true';\n  videoElement.src = URL.createObjectURL(stream);\n\n  videoElement.addEventListener('loadedmetadata', () => {\n    videoElement.play();\n    canvas.width = videoElement.videoWidth;\n    canvas.height = videoElement.videoHeight;\n    videoElementLoaded = true;\n    if (initialFilter) {\n      selectedFilter = initialFilter(videoElement, canvas);\n    }\n  });\n\n  const canvasStream = canvas.captureStream();\n  if (stream.getAudioTracks().length) {\n    // Add the audio track to the stream\n    // This actually doesn't work in Firefox until version 49\n    // https://bugzilla.mozilla.org/show_bug.cgi?id=1271669\n    canvasStream.addTrack(stream.getAudioTracks()[0]);\n  }\n  return canvasStream;\n});\n\n\nmodule.exports = iFilter => {\n  initialFilter = iFilter;\n  if (videoElementLoaded) {\n    selectedFilter = initialFilter(videoElement, canvas);\n  }\n  return {\n    setPublisher: publisher => {\n      // We insert the canvas into the publisher element. captureStream() only works\n      // with Canvas elements that are visible and in the DOM.\n      const pubEl = document.querySelector(`#${publisher.id}`);\n      pubEl.appendChild(canvas);\n      publisher.on('destroyed', () => {\n        // Stop running the filter\n        if (selectedFilter) {\n          selectedFilter.stop();\n        }\n      });\n    },\n    change: filter => {\n      if (selectedFilter) {\n        selectedFilter.stop();\n      }\n      selectedFilter = filter(videoElement, canvas);\n    },\n  };\n};\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ../src/filter.js\n ** module id = 6\n ** module chunks = 1\n **/","\n// Takes a mockOnStreamAvailable function which when given a webrtcstream returns a new stream\n// to replace it with.\nmodule.exports = function mockGetUserMedia(mockOnStreamAvailable) {\n  let oldGetUserMedia;\n  if (navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia) {\n    oldGetUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia ||\n      navigator.mozGetUserMedia;\n    navigator.webkitGetUserMedia = navigator.getUserMedia = navigator.mozGetUserMedia =\n      function getUserMedia(constraints, onStreamAvailable, onStreamAvailableError,\n        onAccessDialogOpened, onAccessDialogClosed, onAccessDenied) {\n        return oldGetUserMedia.call(navigator, constraints, stream => {\n          onStreamAvailable(mockOnStreamAvailable(stream));\n        }, onStreamAvailableError,\n        onAccessDialogOpened, onAccessDialogClosed, onAccessDenied);\n      };\n  } else {\n    console.warn('Could not find getUserMedia function to mock out');\n  }\n};\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ../src/mock-get-user-media.js\n ** module id = 7\n ** module chunks = 1\n **/"],"sourceRoot":""}